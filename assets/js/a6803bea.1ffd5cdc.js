"use strict";(self.webpackChunkdocusaurus_tsx=self.webpackChunkdocusaurus_tsx||[]).push([[9455],{9198:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>n,metadata:()=>c,toc:()=>a});var r=t(4848),i=t(8453);const n={},l="Data Loaders",c={id:"reference/Core API/dataloaders",title:"Data Loaders",description:"Data Iterator",source:"@site/docs/reference/Core API/1_dataloaders.md",sourceDirName:"reference/Core API",slug:"/reference/Core API/dataloaders",permalink:"/eole/docs/reference/Core API/dataloaders",draft:!1,unlisted:!1,editUrl:"https://github.com/eole-nlp/eole/tree/main/docs/docs/reference/Core API/1_dataloaders.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{},sidebar:"apiSidebar",previous:{title:"Modules",permalink:"/eole/docs/reference/Core API/modules"},next:{title:"Prediction",permalink:"/eole/docs/reference/Core API/inference"}},o={},a=[{value:"Data Iterator",id:"data-iterator",level:2},{value:"<em>class</em> eole.inputters.DynamicDatasetIter(corpora, corpora_info, transforms, vocabs, task, batch_type, batch_size, batch_size_multiple, data_type=&#39;text&#39;, bucket_size=2048, bucket_size_init=-1, bucket_size_increment=0, device=device(type=&#39;cpu&#39;), skip_empty_level=&#39;warning&#39;, stride=1, offset=0, score_threshold=0)[source]",id:"class-eoleinputtersdynamicdatasetitercorpora-corpora_info-transforms-vocabs-task-batch_type-batch_size-batch_size_multiple-data_typetext-bucket_size2048-bucket_size_init-1-bucket_size_increment0-devicedevicetypecpu-skip_empty_levelwarning-stride1-offset0-score_threshold0source",level:3},{value:"batch_iter(data, batch_size, batch_type=&#39;sents&#39;, batch_size_multiple=1)[source]",id:"batch_iterdata-batch_size-batch_typesents-batch_size_multiple1source",level:4},{value:"<em>classmethod</em> from_config(corpora, transforms, vocabs, config, task, device, stride=1, offset=0)[source]",id:"classmethod-from_configcorpora-transforms-vocabs-config-task-device-stride1-offset0source",level:4},{value:"<em>class</em> eole.inputters.MixingStrategy(iterables, weights)[source]",id:"class-eoleinputtersmixingstrategyiterables-weightssource",level:3},{value:"<em>class</em> eole.inputters.SequentialMixer(iterables, weights)[source]",id:"class-eoleinputterssequentialmixeriterables-weightssource",level:3},{value:"<em>class</em> eole.inputters.WeightedMixer(iterables, weights)[source]",id:"class-eoleinputtersweightedmixeriterables-weightssource",level:3},{value:"Dataset",id:"dataset",level:2},{value:"<em>class</em> eole.inputters.ParallelCorpus(name, src, tgt, sco=None, align=None)[source]",id:"class-eoleinputtersparallelcorpusname-src-tgt-sconone-alignnonesource",level:3},{value:"load(offset=0, stride=1)[source]",id:"loadoffset0-stride1source",level:4},{value:"<em>class</em> eole.inputters.ParallelCorpusIterator(corpus, transform, skip_empty_level=&#39;warning&#39;, stride=1, offset=0)[source]",id:"class-eoleinputtersparallelcorpusiteratorcorpus-transform-skip_empty_levelwarning-stride1-offset0source",level:3}];function d(e){const s={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(s.h1,{id:"data-loaders",children:"Data Loaders"}),"\n",(0,r.jsx)(s.h2,{id:"data-iterator",children:"Data Iterator"}),"\n",(0,r.jsxs)(s.h3,{id:"class-eoleinputtersdynamicdatasetitercorpora-corpora_info-transforms-vocabs-task-batch_type-batch_size-batch_size_multiple-data_typetext-bucket_size2048-bucket_size_init-1-bucket_size_increment0-devicedevicetypecpu-skip_empty_levelwarning-stride1-offset0-score_threshold0source",children:[(0,r.jsx)(s.em,{children:"class"})," eole.inputters.DynamicDatasetIter(corpora, corpora_info, transforms, vocabs, task, batch_type, batch_size, batch_size_multiple, data_type='text', bucket_size=2048, bucket_size_init=-1, bucket_size_increment=0, device=device(type='cpu'), skip_empty_level='warning', stride=1, offset=0, score_threshold=0)",(0,r.jsx)(s.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/inputters/dynamic_iterator.py#L93-L376",children:"[source]"})]}),"\n",(0,r.jsxs)(s.p,{children:["Bases: ",(0,r.jsx)(s.code,{children:"IterableDataset"})]}),"\n",(0,r.jsx)(s.p,{children:"Yield batch from (multiple) plain text corpus."}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Parameters:"}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"corpora"})," (",(0,r.jsx)(s.em,{children:"dict"})," *[*",(0,r.jsx)(s.em,{children:"str"})," ",(0,r.jsx)(s.em,{children:","})," ",(0,r.jsx)(s.a,{href:"#eole.inputters.ParallelCorpus",children:(0,r.jsx)(s.em,{children:"ParallelCorpus"})})," ",(0,r.jsx)(s.em,{children:"]"}),") \u2013 collections of corpora to iterate;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"corpora_info"})," (",(0,r.jsx)(s.em,{children:"dict"})," *[*",(0,r.jsx)(s.em,{children:"str"})," ",(0,r.jsx)(s.em,{children:","})," ",(0,r.jsx)(s.em,{children:"dict"})," ",(0,r.jsx)(s.em,{children:"]"}),") \u2013 corpora infos correspond to corpora;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"transforms"})," (",(0,r.jsx)(s.em,{children:"dict"})," *[*",(0,r.jsx)(s.em,{children:"str"})," ",(0,r.jsx)(s.em,{children:","})," ",(0,r.jsx)(s.em,{children:"Transform"})," ",(0,r.jsx)(s.em,{children:"]"}),") \u2013 transforms may be used by corpora;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"vocabs"})," (",(0,r.jsx)(s.em,{children:"dict"})," *[*",(0,r.jsx)(s.em,{children:"str"})," ",(0,r.jsx)(s.em,{children:","})," ",(0,r.jsx)(s.em,{children:"Vocab"})," ",(0,r.jsx)(s.em,{children:"]"}),") \u2013 vocab dict for convert corpora into Tensor;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"task"})," (",(0,r.jsx)(s.em,{children:"str"}),") \u2013 CorpusTask.TRAIN/VALID/INFER;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"batch_type"})," (",(0,r.jsx)(s.em,{children:"str"}),") \u2013 batching type to count on, choices=[tokens, sents];"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"batch_size"})," (",(0,r.jsx)(s.em,{children:"int"}),") \u2013 numbers of examples in a batch;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"batch_size_multiple"})," (",(0,r.jsx)(s.em,{children:"int"}),") \u2013 make batch size multiply of this;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"data_type"})," (",(0,r.jsx)(s.em,{children:"str"}),") \u2013 input data type, currently only text;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"bucket_size"})," (",(0,r.jsx)(s.em,{children:"int"}),") \u2013 accum this number of examples in a dynamic dataset;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"bucket_size_init"})," (",(0,r.jsx)(s.em,{children:"int"}),") \u2013 initialize the bucket with this"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"examples;"})," (",(0,r.jsx)(s.em,{children:"size with this amount of"}),")"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"bucket_size_increment"})," (",(0,r.jsx)(s.em,{children:"int"}),") \u2013 increment the bucket"]}),"\n",(0,r.jsx)(s.li,{children:(0,r.jsx)(s.strong,{children:"examples;"})}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"skip_empty_level"})," (",(0,r.jsx)(s.em,{children:"str"}),") \u2013 security level when encouter empty line;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"stride"})," (",(0,r.jsx)(s.em,{children:"int"}),") \u2013 iterate data files with this stride;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"offset"})," (",(0,r.jsx)(s.em,{children:"int"}),") \u2013 iterate data files with this offset."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Variables:"}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"sort_key"})," (",(0,r.jsx)(s.em,{children:"function"}),") \u2013 functions define how to sort examples;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"mixer"})," (",(0,r.jsx)(s.a,{href:"#eole.inputters.MixingStrategy",children:(0,r.jsx)(s.em,{children:"MixingStrategy"})}),") \u2013 the strategy to iterate corpora."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(s.h4,{id:"batch_iterdata-batch_size-batch_typesents-batch_size_multiple1source",children:["batch_iter(data, batch_size, batch_type='sents', batch_size_multiple=1)",(0,r.jsx)(s.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/inputters/dynamic_iterator.py#L300-L350",children:"[source]"})]}),"\n",(0,r.jsx)(s.p,{children:"Yield elements from data in chunks of batch_size,\nwhere each chunk size is a multiple of batch_size_multiple."}),"\n",(0,r.jsxs)(s.h4,{id:"classmethod-from_configcorpora-transforms-vocabs-config-task-device-stride1-offset0source",children:[(0,r.jsx)(s.em,{children:"classmethod"})," from_config(corpora, transforms, vocabs, config, task, device, stride=1, offset=0)",(0,r.jsx)(s.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/inputters/dynamic_iterator.py#L170-L232",children:"[source]"})]}),"\n",(0,r.jsx)(s.p,{children:"Initilize DynamicDatasetIter with options parsed from opt."}),"\n",(0,r.jsxs)(s.h3,{id:"class-eoleinputtersmixingstrategyiterables-weightssource",children:[(0,r.jsx)(s.em,{children:"class"})," eole.inputters.MixingStrategy(iterables, weights)",(0,r.jsx)(s.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/inputters/dynamic_iterator.py#L18-L34",children:"[source]"})]}),"\n",(0,r.jsxs)(s.p,{children:["Bases: ",(0,r.jsx)(s.code,{children:"object"})]}),"\n",(0,r.jsx)(s.p,{children:"Mixing strategy that should be used in Data Iterator."}),"\n",(0,r.jsxs)(s.h3,{id:"class-eoleinputterssequentialmixeriterables-weightssource",children:[(0,r.jsx)(s.em,{children:"class"})," eole.inputters.SequentialMixer(iterables, weights)",(0,r.jsx)(s.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/inputters/dynamic_iterator.py#L37-L48",children:"[source]"})]}),"\n",(0,r.jsxs)(s.p,{children:["Bases: ",(0,r.jsx)(s.a,{href:"#eole.inputters.MixingStrategy",children:(0,r.jsx)(s.code,{children:"MixingStrategy"})})]}),"\n",(0,r.jsx)(s.p,{children:"Generate data sequentially from iterables which is exhaustible."}),"\n",(0,r.jsxs)(s.h3,{id:"class-eoleinputtersweightedmixeriterables-weightssource",children:[(0,r.jsx)(s.em,{children:"class"})," eole.inputters.WeightedMixer(iterables, weights)",(0,r.jsx)(s.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/inputters/dynamic_iterator.py#L51-L90",children:"[source]"})]}),"\n",(0,r.jsxs)(s.p,{children:["Bases: ",(0,r.jsx)(s.a,{href:"#eole.inputters.MixingStrategy",children:(0,r.jsx)(s.code,{children:"MixingStrategy"})})]}),"\n",(0,r.jsx)(s.p,{children:"A mixing strategy that mix data weightedly and iterate infinitely."}),"\n",(0,r.jsx)(s.h2,{id:"dataset",children:"Dataset"}),"\n",(0,r.jsxs)(s.h3,{id:"class-eoleinputtersparallelcorpusname-src-tgt-sconone-alignnonesource",children:[(0,r.jsx)(s.em,{children:"class"})," eole.inputters.ParallelCorpus(name, src, tgt, sco=None, align=None)",(0,r.jsx)(s.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/inputters/text_corpus.py#L95-L161",children:"[source]"})]}),"\n",(0,r.jsxs)(s.p,{children:["Bases: ",(0,r.jsx)(s.code,{children:"object"})]}),"\n",(0,r.jsx)(s.p,{children:"A parallel corpus file pair that can be loaded to iterate."}),"\n",(0,r.jsxs)(s.h4,{id:"loadoffset0-stride1source",children:["load(offset=0, stride=1)",(0,r.jsx)(s.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/inputters/text_corpus.py#L106-L157",children:"[source]"})]}),"\n",(0,r.jsx)(s.p,{children:"Load file and iterate by lines.\noffset and stride allow to iterate only on every\nstride example, starting from offset."}),"\n",(0,r.jsxs)(s.h3,{id:"class-eoleinputtersparallelcorpusiteratorcorpus-transform-skip_empty_levelwarning-stride1-offset0source",children:[(0,r.jsx)(s.em,{children:"class"})," eole.inputters.ParallelCorpusIterator(corpus, transform, skip_empty_level='warning', stride=1, offset=0)",(0,r.jsx)(s.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/inputters/text_corpus.py#L212-L273",children:"[source]"})]}),"\n",(0,r.jsxs)(s.p,{children:["Bases: ",(0,r.jsx)(s.code,{children:"object"})]}),"\n",(0,r.jsx)(s.p,{children:"An iterator dedicated to ParallelCorpus."}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Parameters:"}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"corpus"})," (",(0,r.jsx)(s.a,{href:"#eole.inputters.ParallelCorpus",children:(0,r.jsx)(s.em,{children:"ParallelCorpus"})}),") \u2013 corpus to iterate;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"transform"})," (",(0,r.jsx)(s.em,{children:"TransformPipe"}),") \u2013 transforms to be applied to corpus;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"skip_empty_level"})," (",(0,r.jsx)(s.em,{children:"str"}),") \u2013 security level when encouter empty line;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"stride"})," (",(0,r.jsx)(s.em,{children:"int"}),") \u2013 iterate corpus with this line stride;"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"offset"})," (",(0,r.jsx)(s.em,{children:"int"}),") \u2013 iterate corpus with this line offset."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,r.jsx)(s,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,s,t)=>{t.d(s,{R:()=>l,x:()=>c});var r=t(6540);const i={},n=r.createContext(i);function l(e){const s=r.useContext(n);return r.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function c(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),r.createElement(n.Provider,{value:s},e.children)}}}]);