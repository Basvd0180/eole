"use strict";(self.webpackChunkdocusaurus_tsx=self.webpackChunkdocusaurus_tsx||[]).push([[1829],{5156:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>h,frontMatter:()=>l,metadata:()=>c,toc:()=>t});var s=o(4848),r=o(8453);const l={},i="Modules",c={id:"reference/Core API/modules",title:"Modules",description:"Embeddings",source:"@site/docs/reference/Core API/0_modules.md",sourceDirName:"reference/Core API",slug:"/reference/Core API/modules",permalink:"/eole/docs/reference/Core API/modules",draft:!1,unlisted:!1,editUrl:"https://github.com/eole-nlp/eole/tree/main/docs/docs/reference/Core API/0_modules.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{},sidebar:"apiSidebar",previous:{title:"Framework",permalink:"/eole/docs/reference/Core API/core"},next:{title:"Data Loaders",permalink:"/eole/docs/reference/Core API/dataloaders"}},d={},t=[{value:"Embeddings",id:"embeddings",level:2},{value:"<em>class</em> eole.modules.Embeddings(word_vec_size, word_vocab_size, word_padding_idx, position_encoding=False, position_encoding_type=&#39;SinusoidalInterleaved&#39;, dropout=0, sparse=False, freeze_word_vecs=False)[source]",id:"class-eolemodulesembeddingsword_vec_size-word_vocab_size-word_padding_idx-position_encodingfalse-position_encoding_typesinusoidalinterleaved-dropout0-sparsefalse-freeze_word_vecsfalsesource",level:3},{value:"forward(source, step=None)[source]",id:"forwardsource-stepnonesource",level:4},{value:"load_pretrained_vectors(emb_file)[source]",id:"load_pretrained_vectorsemb_filesource",level:4},{value:"<em>class</em> eole.modules.PositionalEncoding(dim, enc_type, max_len=5000)[source]",id:"class-eolemodulespositionalencodingdim-enc_type-max_len5000source",level:3},{value:"forward(emb, step=None)[source]",id:"forwardemb-stepnonesource",level:4},{value:"<em>class</em> eole.modules.position_ffn.PositionwiseFeedForward(model_config, running_config=None)[source]",id:"class-eolemodulesposition_ffnpositionwisefeedforwardmodel_config-running_confignonesource",level:3},{value:"forward(x)[source]",id:"forwardxsource",level:4},{value:"Encoders",id:"encoders",level:2},{value:"<em>class</em> eole.encoders.EncoderBase(*args, **kwargs)[source]",id:"class-eoleencodersencoderbaseargs-kwargssource",level:3},{value:"forward(emb, mask=None)[source]",id:"forwardemb-masknonesource",level:4},{value:"<em>class</em> eole.encoders.TransformerEncoder(model_config, running_config=None)[source]",id:"class-eoleencoderstransformerencodermodel_config-running_confignonesource",level:3},{value:"forward(emb, mask=None)[source]",id:"forwardemb-masknonesource-1",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource",level:4},{value:"<em>class</em> eole.encoders.RNNEncoder(model_config, running_config=None)[source]",id:"class-eoleencodersrnnencodermodel_config-running_confignonesource",level:3},{value:"forward(emb, mask=None)[source]",id:"forwardemb-masknonesource-2",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-1",level:4},{value:"<em>class</em> eole.encoders.CNNEncoder(model_config, running_config=None)[source]",id:"class-eoleencoderscnnencodermodel_config-running_confignonesource",level:3},{value:"forward(emb, mask=None)[source]",id:"forwardemb-masknonesource-3",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-2",level:4},{value:"<em>class</em> eole.encoders.MeanEncoder(model_config, running_config=None)[source]",id:"class-eoleencodersmeanencodermodel_config-running_confignonesource",level:3},{value:"forward(emb, mask=None)[source]",id:"forwardemb-masknonesource-4",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-3",level:4},{value:"Decoders",id:"decoders",level:2},{value:"<em>class</em> eole.decoders.DecoderBase(attentional=True)[source]",id:"class-eoledecodersdecoderbaseattentionaltruesource",level:3},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-4",level:4},{value:"<em>class</em> eole.decoders.TransformerDecoder(model_config, running_config=None)[source]",id:"class-eoledecoderstransformerdecodermodel_config-running_confignonesource",level:3},{value:"forward(emb, **kwargs)[source]",id:"forwardemb-kwargssource",level:4},{value:"<em>class</em> eole.decoders.rnn_decoder.RNNDecoderBase(model_config, running_config=None)[source]",id:"class-eoledecodersrnn_decoderrnndecoderbasemodel_config-running_confignonesource",level:3},{value:"forward(emb, enc_out, src_len=None, step=None, **kwargs)[source]",id:"forwardemb-enc_out-src_lennone-stepnone-kwargssource",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-5",level:4},{value:"init_state(**kwargs)[source]",id:"init_statekwargssource",level:4},{value:"<em>class</em> eole.decoders.StdRNNDecoder(model_config, running_config=None)[source]",id:"class-eoledecodersstdrnndecodermodel_config-running_confignonesource",level:3},{value:"<em>class</em> eole.decoders.InputFeedRNNDecoder(model_config, running_config=None)[source]",id:"class-eoledecodersinputfeedrnndecodermodel_config-running_confignonesource",level:3},{value:"<em>class</em> eole.decoders.CNNDecoder(model_config, running_config=None)[source]",id:"class-eoledecoderscnndecodermodel_config-running_confignonesource",level:3},{value:"forward(emb, enc_out, step=None, **kwargs)[source]",id:"forwardemb-enc_out-stepnone-kwargssource",level:4},{value:"<em>classmethod</em> from_config(model_config, running_config=None)[source]",id:"classmethod-from_configmodel_config-running_confignonesource-6",level:4},{value:"init_state(**kwargs)[source]",id:"init_statekwargssource-1",level:4},{value:"Attention",id:"attention",level:2},{value:"<em>class</em> eole.modules.GlobalAttention(dim, coverage=False, attn_type=&#39;dot&#39;, attn_func=&#39;softmax&#39;)[source]",id:"class-eolemodulesglobalattentiondim-coveragefalse-attn_typedot-attn_funcsoftmaxsource",level:3},{value:"forward(src, enc_out, src_len=None, coverage=None)[source]",id:"forwardsrc-enc_out-src_lennone-coveragenonesource",level:4},{value:"score(h_t, h_s)[source]",id:"scoreh_t-h_ssource",level:4},{value:"<em>class</em> eole.modules.MultiHeadedAttention(model_config, running_config=None, is_decoder: bool = True, attn_type: str | None = None)[source]",id:"class-eolemodulesmultiheadedattentionmodel_config-running_confignone-is_decoder-bool--true-attn_type-str--none--nonesource",level:3},{value:"forward(key: Tensor, value: Tensor, query: Tensor, mask: Tensor | None = None, sliding_window: int | None = 0, step: int | None = 0, return_attn: bool | None = False)[source]",id:"forwardkey-tensor-value-tensor-query-tensor-mask-tensor--none--none-sliding_window-int--none--0-step-int--none--0-return_attn-bool--none--falsesource",level:4},{value:"<em>class</em> eole.modules.AverageAttention(model_dim, dropout=0.1, aan_useffn=False, pos_ffn_activation_fn=ActivationFunction.relu)[source]",id:"class-eolemodulesaverageattentionmodel_dim-dropout01-aan_useffnfalse-pos_ffn_activation_fnactivationfunctionrelusource",level:3},{value:"forward(layer_in, mask=None, step=None)[source]",id:"forwardlayer_in-masknone-stepnonesource",level:4},{value:"<em>class</em> eole.modules.ConvMultiStepAttention(input_size)[source]",id:"class-eolemodulesconvmultistepattentioninput_sizesource",level:3},{value:"apply_mask(mask)[source]",id:"apply_maskmasksource",level:4},{value:"forward(base_target_emb, input_from_dec, encoder_out_top, encoder_out_combine)[source]",id:"forwardbase_target_emb-input_from_dec-encoder_out_top-encoder_out_combinesource",level:4},{value:"<em>class</em> eole.modules.structured_attention.MatrixTree(eps=1e-05)[source]",id:"class-eolemodulesstructured_attentionmatrixtreeeps1e-05source",level:3},{value:"forward(input)[source]",id:"forwardinputsource",level:4},{value:"NOTE",id:"note",level:4}];function a(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"modules",children:"Modules"}),"\n",(0,s.jsx)(n.h2,{id:"embeddings",children:"Embeddings"}),"\n",(0,s.jsxs)(n.h3,{id:"class-eolemodulesembeddingsword_vec_size-word_vocab_size-word_padding_idx-position_encodingfalse-position_encoding_typesinusoidalinterleaved-dropout0-sparsefalse-freeze_word_vecsfalsesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.modules.Embeddings(word_vec_size, word_vocab_size, word_padding_idx, position_encoding=False, position_encoding_type='SinusoidalInterleaved', dropout=0, sparse=False, freeze_word_vecs=False)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/embeddings.py#L79-L169",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"Words embeddings for encoder/decoder."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"word_vec_size"})," (",(0,s.jsx)(n.em,{children:"int"}),") \u2013 size of the dictionary of embeddings."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"word_vocab_size"})," (",(0,s.jsx)(n.em,{children:"int"}),") \u2013 size of dictionary of embeddings for words."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"word_padding_idx"})," (",(0,s.jsx)(n.em,{children:"int"}),") \u2013 padding index for words in the embeddings."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"position_encoding"})," (",(0,s.jsx)(n.em,{children:"bool"}),") \u2013 see ",(0,s.jsx)(n.a,{href:"#eole.modules.PositionalEncoding",children:(0,s.jsx)(n.code,{children:"PositionalEncoding"})})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"dropout"})," (",(0,s.jsx)(n.em,{children:"float"}),") \u2013 dropout probability."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"sparse"})," (",(0,s.jsx)(n.em,{children:"bool"}),") \u2013 sparse embbedings default False"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"freeze_word_vecs"})," (",(0,s.jsx)(n.em,{children:"bool"}),") \u2013 freeze weights of word vectors."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardsource-stepnonesource",children:["forward(source, step=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/embeddings.py#L150-L166",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Computes the embeddings for words."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsx)(n.strong,{children:"source"})," (",(0,s.jsx)(n.em,{children:"LongTensor"}),") \u2013 index tensor ",(0,s.jsx)(n.code,{children:"(batch, len)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"}),"\nWord embeddings ",(0,s.jsx)(n.code,{children:"(batch, len, embedding_size)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return type:"}),"\nFloatTensor"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"load_pretrained_vectorsemb_filesource",children:["load_pretrained_vectors(emb_file)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/embeddings.py#L133-L148",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Load in pretrained embeddings."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsx)(n.strong,{children:"emb_file"})," (",(0,s.jsx)(n.em,{children:"str"}),") \u2013 path to torch serialized embeddings"]}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"class-eolemodulespositionalencodingdim-enc_type-max_len5000source",children:[(0,s.jsx)(n.em,{children:"class"})," eole.modules.PositionalEncoding(dim, enc_type, max_len=5000)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/embeddings.py#L14-L76",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"Sinusoidal positional encoding for non-recurrent neural networks."}),"\n",(0,s.jsx)(n.p,{children:"Implementation based on \u201cAttention Is All You Need\u201d\n[]"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsx)(n.strong,{children:"dim"})," (",(0,s.jsx)(n.em,{children:"int"}),") \u2013 embedding size"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardemb-stepnonesource",children:["forward(emb, step=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/embeddings.py#L57-L76",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Embed inputs."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"emb"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 Sequence of word vectors\n",(0,s.jsx)(n.code,{children:"(batch_size, seq_len, self.dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"step"})," (",(0,s.jsx)(n.em,{children:"int"})," ",(0,s.jsx)(n.em,{children:"or"})," ",(0,s.jsx)(n.em,{children:"NoneType"}),") \u2013 If stepwise (",(0,s.jsx)(n.code,{children:"seq_len = 1"}),"), use\nthe encoding for this position."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"class-eolemodulesposition_ffnpositionwisefeedforwardmodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.modules.position_ffn.PositionwiseFeedForward(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/position_ffn.py#L28-L123",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"A two-layer Feed-Forward-Network with residual layer norm."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model_config"})," \u2013 eole.config.models.ModelConfig object"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"running_config"})," \u2013 TrainingConfig or InferenceConfig derived from RunningConfig"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardxsource",children:["forward(x)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/position_ffn.py#L93-L119",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Layer definition."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsx)(n.strong,{children:"x"})," \u2013 ",(0,s.jsx)(n.code,{children:"(batch_size, input_len, model_dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"}),"\nOutput ",(0,s.jsx)(n.code,{children:"(batch_size, input_len, model_dim)"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return type:"}),"\n(FloatTensor)"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"encoders",children:"Encoders"}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoleencodersencoderbaseargs-kwargssource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.encoders.EncoderBase(*args, **kwargs)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/encoder.py#L6-L37",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"Base encoder class. Specifies the interface used by different encoder types\nand required by :class:\neole.Models.EncoderDecoderModel\neole.Models.EncoderModel"}),"\n",(0,s.jsxs)(n.h4,{id:"forwardemb-masknonesource",children:["forward(emb, mask=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/encoder.py#L19-L37",children:"[source]"})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"emb"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 embeddings ",(0,s.jsx)(n.code,{children:"(batch, src_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"mask"})," (",(0,s.jsx)(n.em,{children:"BoolTensor"}),") \u2013 mask ",(0,s.jsx)(n.code,{children:"(batch, maxlen)"})," False when value, True when pad"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["enc_out (encoder output used for attention),\n",(0,s.jsx)(n.code,{children:"(batch, src_len, hidden_size)"}),"\nfor bidirectional rnn last dimension is 2x hidden_size"]}),"\n",(0,s.jsxs)(n.li,{children:["enc_final_hs: encoder final hidden state\n",(0,s.jsx)(n.code,{children:"(num_layers x dir, batch, hidden_size)"}),"\nIn the case of LSTM this is a tuple."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return type:"}),"\n(FloatTensor, FloatTensor, FloatTensor)"]}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoleencoderstransformerencodermodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.encoders.TransformerEncoder(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/transformer.py#L89-L160",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.a,{href:"#eole.encoders.EncoderBase",children:(0,s.jsx)(n.code,{children:"EncoderBase"})})]}),"\n",(0,s.jsx)(n.p,{children:"The Transformer encoder from \u201cAttention is All You Need\u201d\n[]"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model_config"})," (",(0,s.jsx)(n.em,{children:"eole.config.TransformerEncoderConfig"}),") \u2013 full encoder config"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"embeddings"})," (",(0,s.jsx)(n.a,{href:"#eole.modules.Embeddings",children:(0,s.jsx)(n.em,{children:"eole.modules.Embeddings"})}),") \u2013 embeddings to use, should have positional encodings"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"running_config"})," (",(0,s.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["enc_out ",(0,s.jsx)(n.code,{children:"(batch_size, src_len, model_dim)"})]}),"\n",(0,s.jsx)(n.li,{children:"encoder final state: None in the case of Transformer"}),"\n",(0,s.jsxs)(n.li,{children:["src_len ",(0,s.jsx)(n.code,{children:"(batch_size)"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return type:"}),"\n(torch.FloatTensor, torch.FloatTensor)"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardemb-masknonesource-1",children:["forward(emb, mask=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/transformer.py#L143-L156",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.a,{href:"#eole.encoders.EncoderBase.forward",children:(0,s.jsx)(n.code,{children:"EncoderBase.forward()"})})]}),"\n",(0,s.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/transformer.py#L135-L141",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoleencodersrnnencodermodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.encoders.RNNEncoder(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/rnn_encoder.py#L8-L97",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.a,{href:"#eole.encoders.EncoderBase",children:(0,s.jsx)(n.code,{children:"EncoderBase"})})]}),"\n",(0,s.jsx)(n.p,{children:"A generic recurrent neural network encoder."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model_config"})," (",(0,s.jsx)(n.em,{children:"eole.config.ModelConfig"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"running_config"})," (",(0,s.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardemb-masknonesource-2",children:["forward(emb, mask=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/rnn_encoder.py#L46-L54",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.a,{href:"#eole.encoders.EncoderBase.forward",children:(0,s.jsx)(n.code,{children:"EncoderBase.forward()"})})]}),"\n",(0,s.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-1",children:[(0,s.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/rnn_encoder.py#L41-L44",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoleencoderscnnencodermodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.encoders.CNNEncoder(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/cnn_encoder.py#L12-L53",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.a,{href:"#eole.encoders.EncoderBase",children:(0,s.jsx)(n.code,{children:"EncoderBase"})})]}),"\n",(0,s.jsx)(n.p,{children:"Encoder based on \u201cConvolutional Sequence to Sequence Learning\u201d\n[]."}),"\n",(0,s.jsxs)(n.h4,{id:"forwardemb-masknonesource-3",children:["forward(emb, mask=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/cnn_encoder.py#L40-L50",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.a,{href:"#eole.encoders.EncoderBase.forward",children:(0,s.jsx)(n.code,{children:"EncoderBase.forward()"})})]}),"\n",(0,s.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-2",children:[(0,s.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/cnn_encoder.py#L31-L38",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoleencodersmeanencodermodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.encoders.MeanEncoder(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/mean_encoder.py#L6-L41",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.a,{href:"#eole.encoders.EncoderBase",children:(0,s.jsx)(n.code,{children:"EncoderBase"})})]}),"\n",(0,s.jsx)(n.p,{children:"A trivial non-recurrent encoder. Simply applies mean pooling."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model_config"})," (",(0,s.jsx)(n.em,{children:"eole.config.ModelConfig"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"embeddings"})," (",(0,s.jsx)(n.a,{href:"#eole.modules.Embeddings",children:(0,s.jsx)(n.em,{children:"eole.modules.Embeddings"})}),") \u2013 embeddings to use, should have positional encodings"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"running_config"})," (",(0,s.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardemb-masknonesource-4",children:["forward(emb, mask=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/mean_encoder.py#L26-L41",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.a,{href:"#eole.encoders.EncoderBase.forward",children:(0,s.jsx)(n.code,{children:"EncoderBase.forward()"})})]}),"\n",(0,s.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-3",children:[(0,s.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/encoders/mean_encoder.py#L20-L24",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,s.jsx)(n.h2,{id:"decoders",children:"Decoders"}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoledecodersdecoderbaseattentionaltruesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.decoders.DecoderBase(attentional=True)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/decoder.py#L4-L33",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"Abstract class for decoders."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsx)(n.strong,{children:"attentional"})," (",(0,s.jsx)(n.em,{children:"bool"}),") \u2013 The decoder returns non-empty attention."]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-4",children:[(0,s.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/decoder.py#L17-L24",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,s.jsx)(n.p,{children:"Subclasses should override this method."}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoledecoderstransformerdecodermodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.decoders.TransformerDecoder(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/transformer_decoder.py#L138-L258",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"TransformerDecoderBase"})]}),"\n",(0,s.jsx)(n.p,{children:"The Transformer decoder from \u201cAttention is All You Need\u201d.\n[]"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model_config"})," (",(0,s.jsx)(n.em,{children:"eole.config.TransformerDecoderConfig"}),") \u2013 full decoder config"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"embeddings"})," (",(0,s.jsx)(n.a,{href:"#eole.modules.Embeddings",children:(0,s.jsx)(n.em,{children:"eole.modules.Embeddings"})}),") \u2013 embeddings to use, should have positional encodings"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"running_config"})," (",(0,s.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardemb-kwargssource",children:["forward(emb, **kwargs)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/transformer_decoder.py#L168-L225",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Decode, possibly stepwise."}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoledecodersrnn_decoderrnndecoderbasemodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.decoders.rnn_decoder.RNNDecoderBase(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L9-L169",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.a,{href:"#eole.decoders.DecoderBase",children:(0,s.jsx)(n.code,{children:"DecoderBase"})})]}),"\n",(0,s.jsx)(n.p,{children:"Base recurrent attention-based decoder class."}),"\n",(0,s.jsxs)(n.p,{children:["Specifies the interface used by different decoder types\nand required by ",(0,s.jsx)(n.a,{href:"/eole/docs/reference/Core%20API/core#eole.models.BaseModel",children:(0,s.jsx)(n.code,{children:"BaseModel"})}),"."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model_config"})," (",(0,s.jsx)(n.em,{children:"eole.config.DecoderConfig"}),") \u2013 full decoder config"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"running_config"})," (",(0,s.jsx)(n.em,{children:"TrainingConfig / InferenceConfig"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardemb-enc_out-src_lennone-stepnone-kwargssource",children:["forward(emb, enc_out, src_len=None, step=None, **kwargs)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L125-L166",children:"[source]"})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"emb"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 input embeddings\n",(0,s.jsx)(n.code,{children:"(batch, tgt_len, dim)"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"enc_out"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 vectors from the encoder\n",(0,s.jsx)(n.code,{children:"(batch, src_len, hidden)"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"src_len"})," (",(0,s.jsx)(n.em,{children:"LongTensor"}),") \u2013 the padded source lengths\n",(0,s.jsx)(n.code,{children:"(batch,)"}),"."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["dec_outs: output from the decoder (after attn)\n",(0,s.jsx)(n.code,{children:"(batch, tgt_len, hidden)"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["attns: distribution over src at each tgt\n",(0,s.jsx)(n.code,{children:"(batch, tgt_len, src_len)"}),"."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return type:"}),"\n(FloatTensor, dict[str, FloatTensor])"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-5",children:[(0,s.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L68-L75",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,s.jsxs)(n.h4,{id:"init_statekwargssource",children:["init_state(**kwargs)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L77-L105",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Initialize decoder state with last state of the encoder."}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoledecodersstdrnndecodermodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.decoders.StdRNNDecoder(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L172-L252",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.a,{href:"#eole.decoders.rnn_decoder.RNNDecoderBase",children:(0,s.jsx)(n.code,{children:"RNNDecoderBase"})})]}),"\n",(0,s.jsx)(n.p,{children:"Standard fully batched RNN decoder with attention."}),"\n",(0,s.jsxs)(n.p,{children:["Faster implementation, uses CuDNN for implementation.\nSee ",(0,s.jsx)(n.code,{children:"RNNDecoderBase"})," for options."]}),"\n",(0,s.jsx)(n.p,{children:"Based around the approach from\n\u201cNeural Machine Translation By Jointly Learning To Align and Translate\u201d\n[]"}),"\n",(0,s.jsx)(n.p,{children:"Implemented without input_feeding and currently with no coverage_attn"}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoledecodersinputfeedrnndecodermodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.decoders.InputFeedRNNDecoder(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/rnn_decoder.py#L255-L334",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.a,{href:"#eole.decoders.rnn_decoder.RNNDecoderBase",children:(0,s.jsx)(n.code,{children:"RNNDecoderBase"})})]}),"\n",(0,s.jsx)(n.p,{children:"Input feeding based decoder."}),"\n",(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.code,{children:"RNNDecoderBase"})," for options."]}),"\n",(0,s.jsx)(n.p,{children:"Based around the input feeding approach from\n\u201cEffective Approaches to Attention-based Neural Machine Translation\u201d\n[]"}),"\n",(0,s.jsxs)(n.h3,{id:"class-eoledecoderscnndecodermodel_config-running_confignonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.decoders.CNNDecoder(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/cnn_decoder.py#L14-L125",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.a,{href:"#eole.decoders.DecoderBase",children:(0,s.jsx)(n.code,{children:"DecoderBase"})})]}),"\n",(0,s.jsx)(n.p,{children:"Decoder based on \u201cConvolutional Sequence to Sequence Learning\u201d\n[]."}),"\n",(0,s.jsx)(n.p,{children:"Consists of residual convolutional layers, with ConvMultiStepAttention."}),"\n",(0,s.jsxs)(n.h4,{id:"forwardemb-enc_out-stepnone-kwargssource",children:["forward(emb, enc_out, step=None, **kwargs)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/cnn_decoder.py#L76-L121",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.code,{children:"eole.modules.RNNDecoderBase.forward()"})]}),"\n",(0,s.jsxs)(n.h4,{id:"classmethod-from_configmodel_config-running_confignonesource-6",children:[(0,s.jsx)(n.em,{children:"classmethod"})," from_config(model_config, running_config=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/cnn_decoder.py#L53-L59",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Alternate constructor."}),"\n",(0,s.jsxs)(n.h4,{id:"init_statekwargssource-1",children:["init_state(**kwargs)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/decoders/cnn_decoder.py#L61-L66",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Init decoder state."}),"\n",(0,s.jsx)(n.h2,{id:"attention",children:"Attention"}),"\n",(0,s.jsxs)(n.h3,{id:"class-eolemodulesglobalattentiondim-coveragefalse-attn_typedot-attn_funcsoftmaxsource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.modules.GlobalAttention(dim, coverage=False, attn_type='dot', attn_func='softmax')",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/global_attention.py#L15-L197",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"Global attention takes a matrix and a query vector. It\nthen computes a parameterized convex combination of the matrix\nbased on the input query."}),"\n",(0,s.jsx)(n.p,{children:"Constructs a unit mapping a query q of size dim\nand a source matrix H of size n x dim, to an output\nof size dim."}),"\n",(0,s.jsx)(n.p,{children:"All models compute the output as\n$c = \\sum_{j=1}^{\\text{SeqLength}} a_j H_j$ where\n$a_j$ is the softmax of a score function.\nThen then apply a projection layer to [q, c]."}),"\n",(0,s.jsx)(n.p,{children:"However they\ndiffer on how they compute the attention score."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Luong Attention (dot, general):\n: * dot: $\\text{score}(H_j,q) = H_j^T q$"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"general: $\\text{score}(H_j, q) = H_j^T W_a q$"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Bahdanau Attention (mlp):\n: * $\\text{score}(H_j, q) = v_a^T \\text{tanh}(W_a q + U_a h_j)$"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"dim"})," (",(0,s.jsx)(n.em,{children:"int"}),") \u2013 dimensionality of query and key"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"coverage"})," (",(0,s.jsx)(n.em,{children:"bool"}),") \u2013 use coverage term"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"attn_type"})," (",(0,s.jsx)(n.em,{children:"str"}),") \u2013 type of attention to use, options [dot,general,mlp]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"attn_func"})," (",(0,s.jsx)(n.em,{children:"str"}),") \u2013 attention function to use, options [softmax,sparsemax]"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardsrc-enc_out-src_lennone-coveragenonesource",children:["forward(src, enc_out, src_len=None, coverage=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/global_attention.py#L134-L197",children:"[source]"})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"src"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 query vectors ",(0,s.jsx)(n.code,{children:"(batch, tgt_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"enc_out"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 encoder out vectors ",(0,s.jsx)(n.code,{children:"(batch, src_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"src_len"})," (",(0,s.jsx)(n.em,{children:"LongTensor"}),") \u2013 source context lengths ",(0,s.jsx)(n.code,{children:"(batch,)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"coverage"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 None (not supported yet)"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Computed vector ",(0,s.jsx)(n.code,{children:"(batch, tgt_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:["Attention distribtutions for each query\n",(0,s.jsx)(n.code,{children:"(batch, tgt_len, src_len)"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return type:"}),"\n(FloatTensor, FloatTensor)"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"scoreh_t-h_ssource",children:["score(h_t, h_s)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/global_attention.py#L100-L132",children:"[source]"})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"h_t"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 sequence of queries ",(0,s.jsx)(n.code,{children:"(batch, tgt_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"h_s"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 sequence of sources ",(0,s.jsx)(n.code,{children:"(batch, src_len, dim"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"}),"\nraw attention scores (unnormalized) for each src index\n: ",(0,s.jsx)(n.code,{children:"(batch, tgt_len, src_len)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return type:"}),"\nFloatTensor"]}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"class-eolemodulesmultiheadedattentionmodel_config-running_confignone-is_decoder-bool--true-attn_type-str--none--nonesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.modules.MultiHeadedAttention(model_config, running_config=None, is_decoder: bool = True, attn_type: str | None = None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/multi_headed_attn.py#L226-L737",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"Multi-Head Attention module from \u201cAttention is All You Need\u201d\n[]."}),"\n",(0,s.jsx)(n.p,{children:"Similar to standard dot attention but uses\nmultiple attention distributions simulataneously\nto select relevant items."}),"\n",(0,s.jsx)(n.p,{children:"Also includes several additional tricks."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model_config"})," \u2013 model_config: eole.config.models.ModelConfig object"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"running_config"})," \u2013 TrainingConfig or InferenceConfig derived from RunningConfig"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"is_decoder"})," \u2013 bool, true if called by the Decoder layers"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"attn_type"})," \u2013 \u201cself\u201d or \u201ccontext\u201d"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardkey-tensor-value-tensor-query-tensor-mask-tensor--none--none-sliding_window-int--none--0-step-int--none--0-return_attn-bool--none--falsesource",children:["forward(key: Tensor, value: Tensor, query: Tensor, mask: Tensor | None = None, sliding_window: int | None = 0, step: int | None = 0, return_attn: bool | None = False)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/multi_headed_attn.py#L407-L737",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Compute the context vector and the attention vectors."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"key"})," (",(0,s.jsx)(n.em,{children:"Tensor"}),") \u2013 set of key_len\nkey vectors ",(0,s.jsx)(n.code,{children:"(batch, key_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"value"})," (",(0,s.jsx)(n.em,{children:"Tensor"}),") \u2013 set of key_len\nvalue vectors ",(0,s.jsx)(n.code,{children:"(batch, key_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"query"})," (",(0,s.jsx)(n.em,{children:"Tensor"}),") \u2013 set of query_len\nquery vectors  ",(0,s.jsx)(n.code,{children:"(batch, query_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"mask"})," \u2013 binary mask 1/0 indicating which keys have\nzero / non-zero attention ",(0,s.jsx)(n.code,{children:"(batch, query_len, key_len)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"step"})," (",(0,s.jsx)(n.em,{children:"int"}),") \u2013 decoding step (used for Rotary embedding)"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["output context vectors ",(0,s.jsx)(n.code,{children:"(batch, query_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:["Attention vector in heads ",(0,s.jsx)(n.code,{children:"(batch, head, query_len, key_len)"}),"."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return type:"}),"\n(Tensor, Tensor)"]}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"class-eolemodulesaverageattentionmodel_dim-dropout01-aan_useffnfalse-pos_ffn_activation_fnactivationfunctionrelusource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.modules.AverageAttention(model_dim, dropout=0.1, aan_useffn=False, pos_ffn_activation_fn=ActivationFunction.relu)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/average_attn.py#L63-L126",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"Average Attention module from\n\u201cAccelerating Neural Transformer via an Average Attention Network\u201d\n[]."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model_dim"})," (",(0,s.jsx)(n.em,{children:"int"}),") \u2013 the dimension of keys/values/queries,\nmust be divisible by head_count"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"dropout"})," (",(0,s.jsx)(n.em,{children:"float"}),") \u2013 dropout parameter"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"pos_ffn_activation_fn"})," (",(0,s.jsx)(n.em,{children:"ActivationFunction"}),") \u2013 activation function choice for PositionwiseFeedForward layer"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h4,{id:"forwardlayer_in-masknone-stepnonesource",children:["forward(layer_in, mask=None, step=None)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/average_attn.py#L96-L126",children:"[source]"})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsx)(n.strong,{children:"layer_in"})," (",(0,s.jsx)(n.em,{children:"FloatTensor"}),") \u2013 ",(0,s.jsx)(n.code,{children:"(batch, t_len, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["gating_out ",(0,s.jsx)(n.code,{children:"(batch, tlen, dim)"})]}),"\n",(0,s.jsxs)(n.li,{children:["average_out average attention\n: ",(0,s.jsx)(n.code,{children:"(batch, input_len, dim)"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Return type:"}),"\n(FloatTensor, FloatTensor)"]}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"class-eolemodulesconvmultistepattentioninput_sizesource",children:[(0,s.jsx)(n.em,{children:"class"})," eole.modules.ConvMultiStepAttention(input_size)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/conv_multi_step_attention.py#L17-L64",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"Conv attention takes a key matrix, a value matrix and a query vector.\nAttention weight is calculated by key matrix with the query vector\nand sum on the value matrix. And the same operation is applied\nin each decode conv layer."}),"\n",(0,s.jsxs)(n.h4,{id:"apply_maskmasksource",children:["apply_mask(mask)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/conv_multi_step_attention.py#L30-L32",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Apply mask"}),"\n",(0,s.jsxs)(n.h4,{id:"forwardbase_target_emb-input_from_dec-encoder_out_top-encoder_out_combinesource",children:["forward(base_target_emb, input_from_dec, encoder_out_top, encoder_out_combine)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/conv_multi_step_attention.py#L34-L64",children:"[source]"})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameters:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"base_target_emb"})," \u2013 target emb tensor\n",(0,s.jsx)(n.code,{children:"(batch, channel, height, width)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"input_from_dec"})," \u2013 output of dec conv\n",(0,s.jsx)(n.code,{children:"(batch, channel, height, width)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"encoder_out_top"})," \u2013 the key matrix for calc of attention weight,\nwhich is the top output of encode conv"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"encoder_out_combine"})," \u2013 the value matrix for the attention-weighted sum,\nwhich is the combination of base emb and top output of encode"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"class-eolemodulesstructured_attentionmatrixtreeeps1e-05source",children:[(0,s.jsx)(n.em,{children:"class"})," eole.modules.structured_attention.MatrixTree(eps=1e-05)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/structured_attention.py#L6-L39",children:"[source]"})]}),"\n",(0,s.jsxs)(n.p,{children:["Bases: ",(0,s.jsx)(n.code,{children:"Module"})]}),"\n",(0,s.jsx)(n.p,{children:"Implementation of the matrix-tree theorem for computing marginals\nof non-projective dependency parsing. This attention layer is used\nin the paper \u201cLearning Structured Text Representations\u201d\n[]."}),"\n",(0,s.jsxs)(n.h4,{id:"forwardinputsource",children:["forward(input)",(0,s.jsx)(n.a,{href:"https://github.com/eole-nlp/eole/blob/master/eole/modules/structured_attention.py#L17-L39",children:"[source]"})]}),"\n",(0,s.jsx)(n.p,{children:"Define the computation performed at every call."}),"\n",(0,s.jsx)(n.p,{children:"Should be overridden by all subclasses."}),"\n",(0,s.jsx)(n.h4,{id:"note",children:"NOTE"}),"\n",(0,s.jsxs)(n.p,{children:["Although the recipe for forward pass needs to be defined within\nthis function, one should call the ",(0,s.jsx)(n.code,{children:"Module"})," instance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them."]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>i,x:()=>c});var s=o(6540);const r={},l=s.createContext(r);function i(e){const n=s.useContext(l);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);