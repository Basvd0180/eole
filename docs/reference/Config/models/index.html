<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-reference/Config/models" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.0">
<title data-rh="true">Models | Eole - üë∑‚Äç‚ôÇÔ∏èüöß Work In Progress</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://eole-nlp.github.io/eole/docs/reference/Config/models"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Models | Eole - üë∑‚Äç‚ôÇÔ∏èüöß Work In Progress"><meta data-rh="true" name="description" content="Base Configs"><meta data-rh="true" property="og:description" content="Base Configs"><link data-rh="true" rel="icon" href="/eole/img/eole-logo.ico"><link data-rh="true" rel="canonical" href="https://eole-nlp.github.io/eole/docs/reference/Config/models"><link data-rh="true" rel="alternate" href="https://eole-nlp.github.io/eole/docs/reference/Config/models" hreflang="en"><link data-rh="true" rel="alternate" href="https://eole-nlp.github.io/eole/docs/reference/Config/models" hreflang="x-default"><link rel="stylesheet" href="/eole/assets/css/styles.0e100862.css">
<script src="/eole/assets/js/runtime~main.2a2fd878.js" defer="defer"></script>
<script src="/eole/assets/js/main.313204b5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/eole/"><div class="navbar__logo"><img src="/eole/img/eole-logo.png" alt="Eole Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/eole/img/eole-logo.png" alt="Eole Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/eole/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/eole/docs/reference/index">Reference</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/eole-nlp/eole" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/eole/docs/reference/index">Eole Core API</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/eole/docs/reference/Config/">Configuration</a><button aria-label="Collapse sidebar category &#x27;Configuration&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/reference/Config/data">Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/reference/Config/inference">Inference</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/eole/docs/reference/Config/models">Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/reference/Config/run">Main Entrypoints</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/reference/Config/training">Training</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/eole/docs/reference/Config/transforms">Transforms</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/eole/docs/reference/Core API/core">Core API</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/eole/docs/reference/bibliography">Bibliography</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/eole/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/eole/docs/reference/Config/"><span itemprop="name">Configuration</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Models</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Models</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="base-configs">Base Configs<a href="#base-configs" class="hash-link" aria-label="Direct link to Base Configs" title="Direct link to Base Configs">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelsbasemodelconfigsource"><em>pydantic model</em> eole.config.models.BaseModelConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L372-L565" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelsbasemodelconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelsbasemodelconfigsource" title="Direct link to pydantic-model-eoleconfigmodelsbasemodelconfigsource">‚Äã</a></h3>
<p>Bases: <code>Config</code></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;BaseModelConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Contains most of the args useful to build the Embeddings module.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;brnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;mean&quot;: &quot;#/$defs/MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;encoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/MeanEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of an encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer_lm&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;decoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of a decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden states. Overwrites [encoder/decoder].hidden_size if set.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in both encoder and decoder (will overwrite enc_layers/dec_layers).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_decoder_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a share weight matrix for the input and output word embeddings in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Decoder Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Share the word embeddings between encoder and decoder. Need to use shared vocabulary for this option.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;input_feed&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Input Feed&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;generator_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Which function to use for generating probabilities over the target vocabulary.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Generator Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_estimator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add estimator layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Estimator&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;left_pad&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable left-padding, useful for some LLMs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Left Pad&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;architecture&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Architecture&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;EmbeddingsConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_enc&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Enc&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_dec&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Dec&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Absolute position encoding, see position_encoding_type. Necessary for non-RNN style models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Encoding&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_shift&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Positions IDS shift before making position embed dirty patch to cover for xlm-roberta-xl&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Shift&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;MeanEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;context_gate&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of context gate to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;source&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;target&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;both&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Context Gate&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bidirectional_encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bidirectional Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;brnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerLMDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Right now just wraps TransformerDecoderConfig for simplicity.\nMight merge in a single class later once TransformerLM path is clarified.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer_lm&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerLMDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.BaseModelConfig.add_estimator"><code>add_estimator (bool)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.architecture"><code>architecture (str | None)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.decoder"><code>decoder (eole.config.models.TransformerDecoderConfig | eole.config.models.TransformerLMDecoderConfig | eole.config.models.RnnDecoderConfig | eole.config.models.CnnDecoderConfig | None)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.embeddings"><code>embeddings (eole.config.models.EmbeddingsConfig)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.encoder"><code>encoder (eole.config.models.TransformerEncoderConfig | eole.config.models.RnnEncoderConfig | eole.config.models.CnnEncoderConfig | eole.config.models.MeanEncoderConfig | None)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.generator_function"><code>generator_function (Literal[&#x27;softmax&#x27;, &#x27;sparsemax&#x27;])</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.hidden_size"><code>hidden_size (int)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.input_feed"><code>input_feed (int)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.layers"><code>layers (int)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.left_pad"><code>left_pad (bool)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.share_decoder_embeddings"><code>share_decoder_embeddings (bool)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.share_embeddings"><code>share_embeddings (bool)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.transformer_ff"><code>transformer_ff (int)</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.word_vec_size"><code>word_vec_size (int)</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong>
<ul>
<li><code>_override_values</code> ¬ª <code>all fields</code></li>
<li><code>_validate_model_config</code> ¬ª <code>all fields</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a> ¬ª <code>all fields</code></li>
<li><a href="#eole.config.models.BaseModelConfig.str_to_dict"><code>str_to_dict</code></a> ¬ª <a href="#eole.config.models.BaseModelConfig.decoder"><code>decoder</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.str_to_dict"><code>str_to_dict</code></a> ¬ª <a href="#eole.config.models.BaseModelConfig.embeddings"><code>embeddings</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.str_to_dict"><code>str_to_dict</code></a> ¬ª <a href="#eole.config.models.BaseModelConfig.encoder"><code>encoder</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-add_estimator--bool--false"><em>field</em> add_estimator <em>: bool</em> <em>= False</em><a href="#field-add_estimator--bool--false" class="hash-link" aria-label="Direct link to field-add_estimator--bool--false" title="Direct link to field-add_estimator--bool--false">‚Äã</a></h4>
<p>Add estimator layer</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-architecture--str--none--none"><em>field</em> architecture <em>: str | None</em> <em>= None</em><a href="#field-architecture--str--none--none" class="hash-link" aria-label="Direct link to field-architecture--str--none--none" title="Direct link to field-architecture--str--none--none">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-decoder--transformerdecoderconfig--transformerlmdecoderconfig--rnndecoderconfig--cnndecoderconfig--none--none"><em>field</em> decoder <em>: <a href="#eole.config.models.TransformerDecoderConfig">TransformerDecoderConfig</a> | <a href="#eole.config.models.TransformerLMDecoderConfig">TransformerLMDecoderConfig</a> | <a href="#eole.config.models.RnnDecoderConfig">RnnDecoderConfig</a> | <a href="#eole.config.models.CnnDecoderConfig">CnnDecoderConfig</a> | None</em> <em>= None</em><a href="#field-decoder--transformerdecoderconfig--transformerlmdecoderconfig--rnndecoderconfig--cnndecoderconfig--none--none" class="hash-link" aria-label="Direct link to field-decoder--transformerdecoderconfig--transformerlmdecoderconfig--rnndecoderconfig--cnndecoderconfig--none--none" title="Direct link to field-decoder--transformerdecoderconfig--transformerlmdecoderconfig--rnndecoderconfig--cnndecoderconfig--none--none">‚Äã</a></h4>
<p>Major parameters of a decoder.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.str_to_dict"><code>str_to_dict</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-embeddings--embeddingsconfig-optional"><em>field</em> embeddings <em>: <a href="#eole.config.models.EmbeddingsConfig">EmbeddingsConfig</a></em> <em>[Optional]</em><a href="#field-embeddings--embeddingsconfig-optional" class="hash-link" aria-label="Direct link to field-embeddings--embeddingsconfig-optional" title="Direct link to field-embeddings--embeddingsconfig-optional">‚Äã</a></h4>
<p>Contains most of the args useful to build the Embeddings module.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.str_to_dict"><code>str_to_dict</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-encoder--transformerencoderconfig--rnnencoderconfig--cnnencoderconfig--meanencoderconfig--none--none"><em>field</em> encoder <em>: <a href="#eole.config.models.TransformerEncoderConfig">TransformerEncoderConfig</a> | <a href="#eole.config.models.RnnEncoderConfig">RnnEncoderConfig</a> | <a href="#eole.config.models.CnnEncoderConfig">CnnEncoderConfig</a> | MeanEncoderConfig | None</em> <em>= None</em><a href="#field-encoder--transformerencoderconfig--rnnencoderconfig--cnnencoderconfig--meanencoderconfig--none--none" class="hash-link" aria-label="Direct link to field-encoder--transformerencoderconfig--rnnencoderconfig--cnnencoderconfig--meanencoderconfig--none--none" title="Direct link to field-encoder--transformerencoderconfig--rnnencoderconfig--cnnencoderconfig--meanencoderconfig--none--none">‚Äã</a></h4>
<p>Major parameters of an encoder.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.str_to_dict"><code>str_to_dict</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-generator_function--literalsoftmax-sparsemax--softmax"><em>field</em> generator_function <em>: Literal[&#x27;softmax&#x27;, &#x27;sparsemax&#x27;]</em> <em>= &#x27;softmax&#x27;</em><a href="#field-generator_function--literalsoftmax-sparsemax--softmax" class="hash-link" aria-label="Direct link to field-generator_function--literalsoftmax-sparsemax--softmax" title="Direct link to field-generator_function--literalsoftmax-sparsemax--softmax">‚Äã</a></h4>
<p>Which function to use for generating probabilities over the target vocabulary.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-hidden_size--int---1"><em>field</em> hidden_size <em>: int</em> <em>= -1</em><a href="#field-hidden_size--int---1" class="hash-link" aria-label="Direct link to field-hidden_size--int---1" title="Direct link to field-hidden_size--int---1">‚Äã</a></h4>
<p>Size of hidden states. Overwrites [encoder/decoder].hidden_size if set.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-input_feed--int--1"><em>field</em> input_feed <em>: int</em> <em>= 1</em><a href="#field-input_feed--int--1" class="hash-link" aria-label="Direct link to field-input_feed--int--1" title="Direct link to field-input_feed--int--1">‚Äã</a></h4>
<p>Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-layers--int---1"><em>field</em> layers <em>: int</em> <em>= -1</em><a href="#field-layers--int---1" class="hash-link" aria-label="Direct link to field-layers--int---1" title="Direct link to field-layers--int---1">‚Äã</a></h4>
<p>Number of layers in both encoder and decoder (will overwrite enc_layers/dec_layers).</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-left_pad--bool--false"><em>field</em> left_pad <em>: bool</em> <em>= False</em><a href="#field-left_pad--bool--false" class="hash-link" aria-label="Direct link to field-left_pad--bool--false" title="Direct link to field-left_pad--bool--false">‚Äã</a></h4>
<p>Enable left-padding, useful for some LLMs.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-share_decoder_embeddings--bool--false"><em>field</em> share_decoder_embeddings <em>: bool</em> <em>= False</em><a href="#field-share_decoder_embeddings--bool--false" class="hash-link" aria-label="Direct link to field-share_decoder_embeddings--bool--false" title="Direct link to field-share_decoder_embeddings--bool--false">‚Äã</a></h4>
<p>Use a share weight matrix for the input and output word embeddings in the decoder.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-share_embeddings--bool--false"><em>field</em> share_embeddings <em>: bool</em> <em>= False</em><a href="#field-share_embeddings--bool--false" class="hash-link" aria-label="Direct link to field-share_embeddings--bool--false" title="Direct link to field-share_embeddings--bool--false">‚Äã</a></h4>
<p>Share the word embeddings between encoder and decoder. Need to use shared vocabulary for this option.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-transformer_ff--int---1"><em>field</em> transformer_ff <em>: int</em> <em>= -1</em><a href="#field-transformer_ff--int---1" class="hash-link" aria-label="Direct link to field-transformer_ff--int---1" title="Direct link to field-transformer_ff--int---1">‚Äã</a></h4>
<p>Size of hidden transformer feed-forward.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-word_vec_size--int---1"><em>field</em> word_vec_size <em>: int</em> <em>= -1</em><a href="#field-word_vec_size--int---1" class="hash-link" aria-label="Direct link to field-word_vec_size--int---1" title="Direct link to field-word_vec_size--int---1">‚Äã</a></h4>
<p>Word embedding size for src and tgt.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-default_architecture----all-fieldssource"><em>validator</em> default_architecture  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L477-L484" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-default_architecture----all-fieldssource" class="hash-link" aria-label="Direct link to validator-default_architecture----all-fieldssource" title="Direct link to validator-default_architecture----all-fieldssource">‚Äã</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-str_to_dict----embeddings--encoder--decodersource"><em>validator</em> str_to_dict  <em>¬ª</em>  <a href="#eole.config.models.BaseModelConfig.embeddings"><em>embeddings</em></a> <em>,</em> <a href="#eole.config.models.BaseModelConfig.encoder"><em>encoder</em></a> <em>,</em> <a href="#eole.config.models.BaseModelConfig.decoder"><em>decoder</em></a><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L457-L466" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-str_to_dict----embeddings--encoder--decodersource" class="hash-link" aria-label="Direct link to validator-str_to_dict----embeddings--encoder--decodersource" title="Direct link to validator-str_to_dict----embeddings--encoder--decodersource">‚Äã</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="update_model_optssource">update_model_opts()<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L486-L524" target="_blank" rel="noopener noreferrer">[source]</a><a href="#update_model_optssource" class="hash-link" aria-label="Direct link to update_model_optssource" title="Direct link to update_model_optssource">‚Äã</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="property-model_type--modeltypesource"><em>property</em> model_type <em>: ModelType</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L448-L455" target="_blank" rel="noopener noreferrer">[source]</a><a href="#property-model_type--modeltypesource" class="hash-link" aria-label="Direct link to property-model_type--modeltypesource" title="Direct link to property-model_type--modeltypesource">‚Äã</a></h4>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelsembeddingsconfigsource"><em>pydantic model</em> eole.config.models.EmbeddingsConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L13-L63" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelsembeddingsconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelsembeddingsconfigsource" title="Direct link to pydantic-model-eoleconfigmodelsembeddingsconfigsource">‚Äã</a></h3>
<p>Bases: <code>Config</code></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;freeze_word_vecs_enc&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Freeze Word Vecs Enc&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;freeze_word_vecs_dec&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Freeze Word Vecs Dec&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;position_encoding&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Absolute position encoding, see position_encoding_type. Necessary for non-RNN style models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Position Encoding&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;position_shift&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Positions IDS shift before making position embed dirty patch to cover for xlm-roberta-xl&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Position Shift&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.freeze_word_vecs_dec"><code>freeze_word_vecs_dec (bool)</code></a></li>
<li><a href="#eole.config.models.EmbeddingsConfig.freeze_word_vecs_enc"><code>freeze_word_vecs_enc (bool)</code></a></li>
<li><a href="#eole.config.models.EmbeddingsConfig.n_positions"><code>n_positions (int | None)</code></a></li>
<li><a href="#eole.config.models.EmbeddingsConfig.position_encoding"><code>position_encoding (bool)</code></a></li>
<li><a href="#eole.config.models.EmbeddingsConfig.position_encoding_type"><code>position_encoding_type (eole.constants.PositionEncodingType | None)</code></a></li>
<li><a href="#eole.config.models.EmbeddingsConfig.position_shift"><code>position_shift (int | None)</code></a></li>
<li><a href="#eole.config.models.EmbeddingsConfig.src_word_vec_size"><code>src_word_vec_size (int)</code></a></li>
<li><a href="#eole.config.models.EmbeddingsConfig.tgt_word_vec_size"><code>tgt_word_vec_size (int)</code></a></li>
<li><a href="#eole.config.models.EmbeddingsConfig.word_vec_size"><code>word_vec_size (int)</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a> ¬ª <code>all fields</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-freeze_word_vecs_dec--bool--false"><em>field</em> freeze_word_vecs_dec <em>: bool</em> <em>= False</em><a href="#field-freeze_word_vecs_dec--bool--false" class="hash-link" aria-label="Direct link to field-freeze_word_vecs_dec--bool--false" title="Direct link to field-freeze_word_vecs_dec--bool--false">‚Äã</a></h4>
<p>Freeze word embeddings on the encoder side.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-freeze_word_vecs_enc--bool--false"><em>field</em> freeze_word_vecs_enc <em>: bool</em> <em>= False</em><a href="#field-freeze_word_vecs_enc--bool--false" class="hash-link" aria-label="Direct link to field-freeze_word_vecs_enc--bool--false" title="Direct link to field-freeze_word_vecs_enc--bool--false">‚Äã</a></h4>
<p>Freeze word embeddings on the encoder side.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-n_positions--int--none--none"><em>field</em> n_positions <em>: int | None</em> <em>= None</em><a href="#field-n_positions--int--none--none" class="hash-link" aria-label="Direct link to field-n_positions--int--none--none" title="Direct link to field-n_positions--int--none--none">‚Äã</a></h4>
<p>Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-position_encoding--bool--false"><em>field</em> position_encoding <em>: bool</em> <em>= False</em><a href="#field-position_encoding--bool--false" class="hash-link" aria-label="Direct link to field-position_encoding--bool--false" title="Direct link to field-position_encoding--bool--false">‚Äã</a></h4>
<p>Absolute position encoding, see position_encoding_type. Necessary for non-RNN style models.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-position_encoding_type--positionencodingtype--none--positionencodingtypesinusoidalinterleaved"><em>field</em> position_encoding_type <em>: PositionEncodingType | None</em> <em>= PositionEncodingType.SinusoidalInterleaved</em><a href="#field-position_encoding_type--positionencodingtype--none--positionencodingtypesinusoidalinterleaved" class="hash-link" aria-label="Direct link to field-position_encoding_type--positionencodingtype--none--positionencodingtypesinusoidalinterleaved" title="Direct link to field-position_encoding_type--positionencodingtype--none--positionencodingtypesinusoidalinterleaved">‚Äã</a></h4>
<p>Type of positional encoding.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-position_shift--int--none--0"><em>field</em> position_shift <em>: int | None</em> <em>= 0</em><a href="#field-position_shift--int--none--0" class="hash-link" aria-label="Direct link to field-position_shift--int--none--0" title="Direct link to field-position_shift--int--none--0">‚Äã</a></h4>
<p>Positions IDS shift before making position embed dirty patch to cover for xlm-roberta-xl</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-src_word_vec_size--int--512"><em>field</em> src_word_vec_size <em>: int</em> <em>= 512</em><a href="#field-src_word_vec_size--int--512" class="hash-link" aria-label="Direct link to field-src_word_vec_size--int--512" title="Direct link to field-src_word_vec_size--int--512">‚Äã</a></h4>
<p>Word embedding size for src.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-tgt_word_vec_size--int--512"><em>field</em> tgt_word_vec_size <em>: int</em> <em>= 512</em><a href="#field-tgt_word_vec_size--int--512" class="hash-link" aria-label="Direct link to field-tgt_word_vec_size--int--512" title="Direct link to field-tgt_word_vec_size--int--512">‚Äã</a></h4>
<p>Word embedding size for tgt.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-word_vec_size--int---1-1"><em>field</em> word_vec_size <em>: int</em> <em>= -1</em><a href="#field-word_vec_size--int---1-1" class="hash-link" aria-label="Direct link to field-word_vec_size--int---1-1" title="Direct link to field-word_vec_size--int---1-1">‚Äã</a></h4>
<p>Word embedding size for src and tgt.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><a href="#eole.config.models.EmbeddingsConfig.validate_embeddings"><code>validate_embeddings</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-validate_embeddings----all-fieldssource"><em>validator</em> validate_embeddings  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L53-L63" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-validate_embeddings----all-fieldssource" class="hash-link" aria-label="Direct link to validator-validate_embeddings----all-fieldssource" title="Direct link to validator-validate_embeddings----all-fieldssource">‚Äã</a></h4>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelsencoderconfigsource"><em>pydantic model</em> eole.config.models.EncoderConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L66-L79" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelsencoderconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelsencoderconfigsource" title="Direct link to pydantic-model-eoleconfigmodelsencoderconfigsource">‚Äã</a></h3>
<p>Bases: <code>Config</code></p>
<p>Abstract class for all encoders</p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;EncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;description&quot;: &quot;Abstract class for all encoders&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of encoder layer(s) to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.EncoderConfig.encoder_type"><code>encoder_type (str | None)</code></a></li>
<li><a href="#eole.config.models.EncoderConfig.hidden_size"><code>hidden_size (int)</code></a></li>
<li><a href="#eole.config.models.EncoderConfig.layers"><code>layers (int)</code></a></li>
<li><a href="#eole.config.models.EncoderConfig.src_word_vec_size"><code>src_word_vec_size (int)</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-encoder_type--str--none--rnn"><em>field</em> encoder_type <em>: str | None</em> <em>= &#x27;rnn&#x27;</em><a href="#field-encoder_type--str--none--rnn" class="hash-link" aria-label="Direct link to field-encoder_type--str--none--rnn" title="Direct link to field-encoder_type--str--none--rnn">‚Äã</a></h4>
<p>Type of encoder layer(s) to use.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-hidden_size--int--512"><em>field</em> hidden_size <em>: int</em> <em>= 512</em><a href="#field-hidden_size--int--512" class="hash-link" aria-label="Direct link to field-hidden_size--int--512" title="Direct link to field-hidden_size--int--512">‚Äã</a></h4>
<p>Size of encoder hidden states.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-layers--int--2"><em>field</em> layers <em>: int</em> <em>= 2</em><a href="#field-layers--int--2" class="hash-link" aria-label="Direct link to field-layers--int--2" title="Direct link to field-layers--int--2">‚Äã</a></h4>
<p>Number of layers in the encoder.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-src_word_vec_size--int--512-1"><em>field</em> src_word_vec_size <em>: int</em> <em>= 512</em><a href="#field-src_word_vec_size--int--512-1" class="hash-link" aria-label="Direct link to field-src_word_vec_size--int--512-1" title="Direct link to field-src_word_vec_size--int--512-1">‚Äã</a></h4>
<p>Word embedding size for src.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelsdecoderconfigsource"><em>pydantic model</em> eole.config.models.DecoderConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L82-L112" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelsdecoderconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelsdecoderconfigsource" title="Direct link to pydantic-model-eoleconfigmodelsdecoderconfigsource">‚Äã</a></h3>
<p>Bases: <code>Config</code></p>
<p>Abstract class for all decoders</p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;DecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;description&quot;: &quot;Abstract class for all decoders&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of decoder layer(s) to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.DecoderConfig.coverage_attn"><code>coverage_attn (bool)</code></a></li>
<li><a href="#eole.config.models.DecoderConfig.decoder_type"><code>decoder_type (str | None)</code></a></li>
<li><a href="#eole.config.models.DecoderConfig.global_attention"><code>global_attention (Literal[&#x27;dot&#x27;, &#x27;general&#x27;, &#x27;mlp&#x27;, None])</code></a></li>
<li><a href="#eole.config.models.DecoderConfig.global_attention_function"><code>global_attention_function (Literal[&#x27;softmax&#x27;, &#x27;sparsemax&#x27;])</code></a></li>
<li><a href="#eole.config.models.DecoderConfig.hidden_size"><code>hidden_size (int)</code></a></li>
<li><a href="#eole.config.models.DecoderConfig.lambda_coverage"><code>lambda_coverage (float)</code></a></li>
<li><a href="#eole.config.models.DecoderConfig.layers"><code>layers (int)</code></a></li>
<li><a href="#eole.config.models.DecoderConfig.tgt_word_vec_size"><code>tgt_word_vec_size (int)</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong>
<ul>
<li><code>_validate_decoder_config</code> ¬ª <code>all fields</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-coverage_attn--bool--false"><em>field</em> coverage_attn <em>: bool</em> <em>= False</em><a href="#field-coverage_attn--bool--false" class="hash-link" aria-label="Direct link to field-coverage_attn--bool--false" title="Direct link to field-coverage_attn--bool--false">‚Äã</a></h4>
<p>Train a coverage attention layer.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-decoder_type--str--none--rnn"><em>field</em> decoder_type <em>: str | None</em> <em>= &#x27;rnn&#x27;</em><a href="#field-decoder_type--str--none--rnn" class="hash-link" aria-label="Direct link to field-decoder_type--str--none--rnn" title="Direct link to field-decoder_type--str--none--rnn">‚Äã</a></h4>
<p>Type of decoder layer(s) to use.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-global_attention--literaldot-general-mlp-none--general"><em>field</em> global_attention <em>: Literal[&#x27;dot&#x27;, &#x27;general&#x27;, &#x27;mlp&#x27;, None]</em> <em>= &#x27;general&#x27;</em><a href="#field-global_attention--literaldot-general-mlp-none--general" class="hash-link" aria-label="Direct link to field-global_attention--literaldot-general-mlp-none--general" title="Direct link to field-global_attention--literaldot-general-mlp-none--general">‚Äã</a></h4>
<p>The attention type to use. (Luong=general, Bahdanau=MLP)</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-global_attention_function--literalsoftmax-sparsemax--softmax"><em>field</em> global_attention_function <em>: Literal[&#x27;softmax&#x27;, &#x27;sparsemax&#x27;]</em> <em>= &#x27;softmax&#x27;</em><a href="#field-global_attention_function--literalsoftmax-sparsemax--softmax" class="hash-link" aria-label="Direct link to field-global_attention_function--literalsoftmax-sparsemax--softmax" title="Direct link to field-global_attention_function--literalsoftmax-sparsemax--softmax">‚Äã</a></h4>
<p>Global attention function to use.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-hidden_size--int--512-1"><em>field</em> hidden_size <em>: int</em> <em>= 512</em><a href="#field-hidden_size--int--512-1" class="hash-link" aria-label="Direct link to field-hidden_size--int--512-1" title="Direct link to field-hidden_size--int--512-1">‚Äã</a></h4>
<p>Size of decoder hidden states.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-lambda_coverage--float--00"><em>field</em> lambda_coverage <em>: float</em> <em>= 0.0</em><a href="#field-lambda_coverage--float--00" class="hash-link" aria-label="Direct link to field-lambda_coverage--float--00" title="Direct link to field-lambda_coverage--float--00">‚Äã</a></h4>
<p>Lambda value for coverage loss of See et al (2017)</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-layers--int--2-1"><em>field</em> layers <em>: int</em> <em>= 2</em><a href="#field-layers--int--2-1" class="hash-link" aria-label="Direct link to field-layers--int--2-1" title="Direct link to field-layers--int--2-1">‚Äã</a></h4>
<p>Number of layers in the decoder.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-tgt_word_vec_size--int--512-1"><em>field</em> tgt_word_vec_size <em>: int</em> <em>= 512</em><a href="#field-tgt_word_vec_size--int--512-1" class="hash-link" aria-label="Direct link to field-tgt_word_vec_size--int--512-1" title="Direct link to field-tgt_word_vec_size--int--512-1">‚Äã</a></h4>
<p>Word embedding size for tgt.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelscustommodelconfigsource"><em>pydantic model</em> eole.config.models.CustomModelConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L568-L573" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelscustommodelconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelscustommodelconfigsource" title="Direct link to pydantic-model-eoleconfigmodelscustommodelconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.BaseModelConfig"><code>BaseModelConfig</code></a></p>
<p>Wrap anything that does not fit a set common architecture.</p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;CustomModelConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;description&quot;: &quot;Wrap anything that does not fit a set common architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Contains most of the args useful to build the Embeddings module.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;brnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;mean&quot;: &quot;#/$defs/MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;encoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/MeanEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of an encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer_lm&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;decoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of a decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden states. Overwrites [encoder/decoder].hidden_size if set.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in both encoder and decoder (will overwrite enc_layers/dec_layers).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_decoder_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a share weight matrix for the input and output word embeddings in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Decoder Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Share the word embeddings between encoder and decoder. Need to use shared vocabulary for this option.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;input_feed&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Input Feed&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;generator_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Which function to use for generating probabilities over the target vocabulary.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Generator Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_estimator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add estimator layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Estimator&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;left_pad&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable left-padding, useful for some LLMs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Left Pad&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;architecture&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;custom&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;custom&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;custom&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Architecture&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;EmbeddingsConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_enc&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Enc&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_dec&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Dec&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Absolute position encoding, see position_encoding_type. Necessary for non-RNN style models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Encoding&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_shift&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Positions IDS shift before making position embed dirty patch to cover for xlm-roberta-xl&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Shift&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;MeanEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;context_gate&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of context gate to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;source&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;target&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;both&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Context Gate&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bidirectional_encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bidirectional Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;brnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerLMDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Right now just wraps TransformerDecoderConfig for simplicity.\nMight merge in a single class later once TransformerLM path is clarified.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer_lm&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerLMDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.CustomModelConfig.architecture"><code>architecture (Literal[&#x27;custom&#x27;])</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-architecture--literalcustom--custom"><em>field</em> architecture <em>: Literal[&#x27;custom&#x27;]</em> <em>= &#x27;custom&#x27;</em><a href="#field-architecture--literalcustom--custom" class="hash-link" aria-label="Direct link to field-architecture--literalcustom--custom" title="Direct link to field-architecture--literalcustom--custom">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.BaseModelConfig.default_architecture"><code>default_architecture</code></a></li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="transformer">Transformer<a href="#transformer" class="hash-link" aria-label="Direct link to Transformer" title="Direct link to Transformer">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelstransformerconfigsource"><em>pydantic model</em> eole.config.models.TransformerConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L201-L295" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelstransformerconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelstransformerconfigsource" title="Direct link to pydantic-model-eoleconfigmodelstransformerconfigsource">  ‚Äã</a></h3>
<p>Bases: <code>Config</code></p>
<p>This base TransformerConfig class regroups parameters than can
both be set at model level or either encoder/decoder level.
BaseModelConfig._override_values validator overrides
encoder/decoder values with model values if relevant.</p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;TransformerConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;description&quot;: &quot;This base TransformerConfig class regroups parameters than can\nboth be set at model level or either encoder/decoder level.\nBaseModelConfig._override_values validator overrides\nencoder/decoder values with model values if relevant.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.TransformerConfig.add_ffnbias"><code>add_ffnbias (bool)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.add_qkvbias"><code>add_qkvbias (bool)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.head_dim"><code>head_dim (int | None)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.heads"><code>heads (int)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.heads_kv"><code>heads_kv (int | None)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.layer_norm"><code>layer_norm (Literal[&#x27;standard&#x27;, &#x27;rms&#x27;])</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.mlp_activation_fn"><code>mlp_activation_fn (eole.constants.ActivationFunction)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.n_positions"><code>n_positions (int | None)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.norm_eps"><code>norm_eps (float)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.num_experts"><code>num_experts (int)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.num_experts_per_tok"><code>num_experts_per_tok (int)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.parallel_residual"><code>parallel_residual (bool)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.position_encoding_type"><code>position_encoding_type (eole.constants.PositionEncodingType | None)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.relative_positions_buckets"><code>relative_positions_buckets (int)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.rope_config"><code>rope_config (eole.config.models.RotaryPositionConfig | None)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.shared_layer_norm"><code>shared_layer_norm (bool)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.sliding_window"><code>sliding_window (int)</code></a></li>
<li><a href="#eole.config.models.TransformerConfig.transformer_ff"><code>transformer_ff (int)</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong>
<ul>
<li><code>_validate_transformer_config</code> ¬ª <code>all fields</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-add_ffnbias--bool--false"><em>field</em> add_ffnbias <em>: bool</em> <em>= False</em><a href="#field-add_ffnbias--bool--false" class="hash-link" aria-label="Direct link to field-add_ffnbias--bool--false" title="Direct link to field-add_ffnbias--bool--false">‚Äã</a></h4>
<p>Add bias to nn.Linear of MLP FFN.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-add_qkvbias--bool--false"><em>field</em> add_qkvbias <em>: bool</em> <em>= False</em><a href="#field-add_qkvbias--bool--false" class="hash-link" aria-label="Direct link to field-add_qkvbias--bool--false" title="Direct link to field-add_qkvbias--bool--false">‚Äã</a></h4>
<p>Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-head_dim--int--none--none"><em>field</em> head_dim <em>: int | None</em> <em>= None</em><a href="#field-head_dim--int--none--none" class="hash-link" aria-label="Direct link to field-head_dim--int--none--none" title="Direct link to field-head_dim--int--none--none">‚Äã</a></h4>
<p>Head dimension when this needs to be different vs hidden_size // heads</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-heads--int--8"><em>field</em> heads <em>: int</em> <em>= 8</em><a href="#field-heads--int--8" class="hash-link" aria-label="Direct link to field-heads--int--8" title="Direct link to field-heads--int--8">‚Äã</a></h4>
<p>Number of heads for transformer self-attention.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-heads_kv--int--none--none"><em>field</em> heads_kv <em>: int | None</em> <em>= None</em><a href="#field-heads_kv--int--none--none" class="hash-link" aria-label="Direct link to field-heads_kv--int--none--none" title="Direct link to field-heads_kv--int--none--none">‚Äã</a></h4>
<p>Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-layer_norm--literalstandard-rms--standard"><em>field</em> layer_norm <em>: Literal[&#x27;standard&#x27;, &#x27;rms&#x27;]</em> <em>= &#x27;standard&#x27;</em><a href="#field-layer_norm--literalstandard-rms--standard" class="hash-link" aria-label="Direct link to field-layer_norm--literalstandard-rms--standard" title="Direct link to field-layer_norm--literalstandard-rms--standard">‚Äã</a></h4>
<p>Type of layer normalization in transformer architecture.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-mlp_activation_fn--activationfunction--activationfunctionrelu"><em>field</em> mlp_activation_fn <em>: ActivationFunction</em> <em>= ActivationFunction.relu</em><a href="#field-mlp_activation_fn--activationfunction--activationfunctionrelu" class="hash-link" aria-label="Direct link to field-mlp_activation_fn--activationfunction--activationfunctionrelu" title="Direct link to field-mlp_activation_fn--activationfunction--activationfunctionrelu">‚Äã</a></h4>
<p>The activation function to use in MLP layer.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-n_positions--int--none--none-1"><em>field</em> n_positions <em>: int | None</em> <em>= None</em><a href="#field-n_positions--int--none--none-1" class="hash-link" aria-label="Direct link to field-n_positions--int--none--none-1" title="Direct link to field-n_positions--int--none--none-1">‚Äã</a></h4>
<p>Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-norm_eps--float--1e-06"><em>field</em> norm_eps <em>: float</em> <em>= 1e-06</em><a href="#field-norm_eps--float--1e-06" class="hash-link" aria-label="Direct link to field-norm_eps--float--1e-06" title="Direct link to field-norm_eps--float--1e-06">‚Äã</a></h4>
<p>Layer norm epsilon.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-num_experts--int--0"><em>field</em> num_experts <em>: int</em> <em>= 0</em><a href="#field-num_experts--int--0" class="hash-link" aria-label="Direct link to field-num_experts--int--0" title="Direct link to field-num_experts--int--0">‚Äã</a></h4>
<p>Number of experts for MoE models.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-num_experts_per_tok--int--2"><em>field</em> num_experts_per_tok <em>: int</em> <em>= 2</em><a href="#field-num_experts_per_tok--int--2" class="hash-link" aria-label="Direct link to field-num_experts_per_tok--int--2" title="Direct link to field-num_experts_per_tok--int--2">‚Äã</a></h4>
<p>Number of experts per token.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-parallel_residual--bool--false"><em>field</em> parallel_residual <em>: bool</em> <em>= False</em><a href="#field-parallel_residual--bool--false" class="hash-link" aria-label="Direct link to field-parallel_residual--bool--false" title="Direct link to field-parallel_residual--bool--false">‚Äã</a></h4>
<p>Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-position_encoding_type--positionencodingtype--none--positionencodingtypesinusoidalinterleaved-1"><em>field</em> position_encoding_type <em>: PositionEncodingType | None</em> <em>= PositionEncodingType.SinusoidalInterleaved</em><a href="#field-position_encoding_type--positionencodingtype--none--positionencodingtypesinusoidalinterleaved-1" class="hash-link" aria-label="Direct link to field-position_encoding_type--positionencodingtype--none--positionencodingtypesinusoidalinterleaved-1" title="Direct link to field-position_encoding_type--positionencodingtype--none--positionencodingtypesinusoidalinterleaved-1">‚Äã</a></h4>
<p>Type of positional encoding.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-relative_positions_buckets--int--0"><em>field</em> relative_positions_buckets <em>: int</em> <em>= 0</em><a href="#field-relative_positions_buckets--int--0" class="hash-link" aria-label="Direct link to field-relative_positions_buckets--int--0" title="Direct link to field-relative_positions_buckets--int--0">‚Äã</a></h4>
<p>Enable relative position bias (<a href="https://github.com/google-research/text-to-text-transfer-transformer" target="_blank" rel="noopener noreferrer">https://github.com/google-research/text-to-text-transfer-transformer</a>).</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-rope_config--rotarypositionconfig--none--none"><em>field</em> rope_config <em>: RotaryPositionConfig | None</em> <em>= None</em><a href="#field-rope_config--rotarypositionconfig--none--none" class="hash-link" aria-label="Direct link to field-rope_config--rotarypositionconfig--none--none" title="Direct link to field-rope_config--rotarypositionconfig--none--none">‚Äã</a></h4>
<p>Rotary position config, if relevant.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-shared_layer_norm--bool--false"><em>field</em> shared_layer_norm <em>: bool</em> <em>= False</em><a href="#field-shared_layer_norm--bool--false" class="hash-link" aria-label="Direct link to field-shared_layer_norm--bool--false" title="Direct link to field-shared_layer_norm--bool--false">‚Äã</a></h4>
<p>Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-sliding_window--int--0"><em>field</em> sliding_window <em>: int</em> <em>= 0</em><a href="#field-sliding_window--int--0" class="hash-link" aria-label="Direct link to field-sliding_window--int--0" title="Direct link to field-sliding_window--int--0">‚Äã</a></h4>
<p>Sliding window for transformer self-attention.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-transformer_ff--int--2048"><em>field</em> transformer_ff <em>: int</em> <em>= 2048</em><a href="#field-transformer_ff--int--2048" class="hash-link" aria-label="Direct link to field-transformer_ff--int--2048" title="Direct link to field-transformer_ff--int--2048">‚Äã</a></h4>
<p>Size of hidden transformer feed-forward.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="property-dim_per_head--intsource"><em>property</em> dim_per_head <em>: int</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L289-L295" target="_blank" rel="noopener noreferrer">[source]</a><a href="#property-dim_per_head--intsource" class="hash-link" aria-label="Direct link to property-dim_per_head--intsource" title="Direct link to property-dim_per_head--intsource">‚Äã</a></h4>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelstransformerencoderconfigsource"><em>pydantic model</em> eole.config.models.TransformerEncoderConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L299-L302" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelstransformerencoderconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelstransformerencoderconfigsource" title="Direct link to pydantic-model-eoleconfigmodelstransformerencoderconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.TransformerConfig"><code>TransformerConfig</code></a>, <a href="#eole.config.models.EncoderConfig"><code>EncoderConfig</code></a></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;TransformerEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.TransformerEncoderConfig.encoder_type"><code>encoder_type (Literal[&#x27;transformer&#x27;])</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-encoder_type--literaltransformer--transformer"><em>field</em> encoder_type <em>: Literal[&#x27;transformer&#x27;]</em> <em>= &#x27;transformer&#x27;</em><a href="#field-encoder_type--literaltransformer--transformer" class="hash-link" aria-label="Direct link to field-encoder_type--literaltransformer--transformer" title="Direct link to field-encoder_type--literaltransformer--transformer">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_transformer_config</code></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelstransformerdecoderconfigsource"><em>pydantic model</em> eole.config.models.TransformerDecoderConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L305-L356" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelstransformerdecoderconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelstransformerdecoderconfigsource" title="Direct link to pydantic-model-eoleconfigmodelstransformerdecoderconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.TransformerConfig"><code>TransformerConfig</code></a>, <a href="#eole.config.models.DecoderConfig"><code>DecoderConfig</code></a></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.TransformerDecoderConfig.aan_useffn"><code>aan_useffn (bool)</code></a></li>
<li><a href="#eole.config.models.TransformerDecoderConfig.alignment_heads"><code>alignment_heads (int)</code></a></li>
<li><a href="#eole.config.models.TransformerDecoderConfig.alignment_layer"><code>alignment_layer (int)</code></a></li>
<li><a href="#eole.config.models.TransformerDecoderConfig.decoder_type"><code>decoder_type (Literal[&#x27;transformer&#x27;])</code></a></li>
<li><a href="#eole.config.models.TransformerDecoderConfig.full_context_alignment"><code>full_context_alignment (bool)</code></a></li>
<li><a href="#eole.config.models.TransformerDecoderConfig.lambda_align"><code>lambda_align (float)</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong>
<ul>
<li><code>_validate_transformer_decoder_config</code> ¬ª <code>all fields</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-aan_useffn--bool--false"><em>field</em> aan_useffn <em>: bool</em> <em>= False</em><a href="#field-aan_useffn--bool--false" class="hash-link" aria-label="Direct link to field-aan_useffn--bool--false" title="Direct link to field-aan_useffn--bool--false">‚Äã</a></h4>
<p>Turn on the FFN layer in the AAN decoder.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
<li><code>_validate_transformer_config</code></li>
<li><code>_validate_transformer_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-alignment_heads--int--0"><em>field</em> alignment_heads <em>: int</em> <em>= 0</em><a href="#field-alignment_heads--int--0" class="hash-link" aria-label="Direct link to field-alignment_heads--int--0" title="Direct link to field-alignment_heads--int--0">‚Äã</a></h4>
<p>Number of cross attention heads per layer to supervise with.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
<li><code>_validate_transformer_config</code></li>
<li><code>_validate_transformer_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-alignment_layer--int---2"><em>field</em> alignment_layer <em>: int</em> <em>= -2</em><a href="#field-alignment_layer--int---2" class="hash-link" aria-label="Direct link to field-alignment_layer--int---2" title="Direct link to field-alignment_layer--int---2">‚Äã</a></h4>
<p>Layer number which has to be supervised.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
<li><code>_validate_transformer_config</code></li>
<li><code>_validate_transformer_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-decoder_type--literaltransformer--transformer"><em>field</em> decoder_type <em>: Literal[&#x27;transformer&#x27;]</em> <em>= &#x27;transformer&#x27;</em><a href="#field-decoder_type--literaltransformer--transformer" class="hash-link" aria-label="Direct link to field-decoder_type--literaltransformer--transformer" title="Direct link to field-decoder_type--literaltransformer--transformer">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
<li><code>_validate_transformer_config</code></li>
<li><code>_validate_transformer_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-full_context_alignment--bool--false"><em>field</em> full_context_alignment <em>: bool</em> <em>= False</em><a href="#field-full_context_alignment--bool--false" class="hash-link" aria-label="Direct link to field-full_context_alignment--bool--false" title="Direct link to field-full_context_alignment--bool--false">‚Äã</a></h4>
<p>Whether alignment is conditioned on full target context.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
<li><code>_validate_transformer_config</code></li>
<li><code>_validate_transformer_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-lambda_align--float--00"><em>field</em> lambda_align <em>: float</em> <em>= 0.0</em><a href="#field-lambda_align--float--00" class="hash-link" aria-label="Direct link to field-lambda_align--float--00" title="Direct link to field-lambda_align--float--00">‚Äã</a></h4>
<p>Lambda value for alignement loss of Garg et al, 2019 (<a href="https://arxiv.org/abs/1909.02074" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/1909.02074</a>)</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
<li><code>_validate_transformer_config</code></li>
<li><code>_validate_transformer_decoder_config</code></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelstransformerlmdecoderconfigsource"><em>pydantic model</em> eole.config.models.TransformerLMDecoderConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L359-L365" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelstransformerlmdecoderconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelstransformerlmdecoderconfigsource" title="Direct link to pydantic-model-eoleconfigmodelstransformerlmdecoderconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.TransformerDecoderConfig"><code>TransformerDecoderConfig</code></a></p>
<p>Right now just wraps TransformerDecoderConfig for simplicity.
Might merge in a single class later once TransformerLM path is clarified.</p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;TransformerLMDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;description&quot;: &quot;Right now just wraps TransformerDecoderConfig for simplicity.\nMight merge in a single class later once TransformerLM path is clarified.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_lm&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.TransformerLMDecoderConfig.decoder_type"><code>decoder_type (Literal[&#x27;transformer_lm&#x27;])</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-decoder_type--literaltransformer_lm--transformer_lm"><em>field</em> decoder_type <em>: Literal[&#x27;transformer_lm&#x27;]</em> <em>= &#x27;transformer_lm&#x27;</em><a href="#field-decoder_type--literaltransformer_lm--transformer_lm" class="hash-link" aria-label="Direct link to field-decoder_type--literaltransformer_lm--transformer_lm" title="Direct link to field-decoder_type--literaltransformer_lm--transformer_lm">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
<li><code>_validate_transformer_config</code></li>
<li><code>_validate_transformer_decoder_config</code></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelstransformermodelconfigsource"><em>pydantic model</em> eole.config.models.TransformerModelConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L635-L669" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelstransformermodelconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelstransformermodelconfigsource" title="Direct link to pydantic-model-eoleconfigmodelstransformermodelconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.TransformerConfig"><code>TransformerConfig</code></a>, <a href="#eole.config.models.BaseModelConfig"><code>BaseModelConfig</code></a></p>
<p>Facilitate setting some transformer specific params at model level.</p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;TransformerModelConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;description&quot;: &quot;Facilitate setting some transformer specific params at model level.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Contains most of the args useful to build the Embeddings module.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;brnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;mean&quot;: &quot;#/$defs/MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;encoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/MeanEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of an encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer_lm&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;decoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of a decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden states. Overwrites [encoder/decoder].hidden_size if set.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in both encoder and decoder (will overwrite enc_layers/dec_layers).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_decoder_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a share weight matrix for the input and output word embeddings in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Decoder Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Share the word embeddings between encoder and decoder. Need to use shared vocabulary for this option.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;input_feed&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Input Feed&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;generator_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Which function to use for generating probabilities over the target vocabulary.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Generator Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_estimator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add estimator layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Estimator&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;left_pad&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable left-padding, useful for some LLMs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Left Pad&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;architecture&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Architecture&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;EmbeddingsConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_enc&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Enc&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_dec&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Dec&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Absolute position encoding, see position_encoding_type. Necessary for non-RNN style models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Encoding&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_shift&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Positions IDS shift before making position embed dirty patch to cover for xlm-roberta-xl&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Shift&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;MeanEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;context_gate&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of context gate to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;source&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;target&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;both&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Context Gate&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bidirectional_encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bidirectional Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;brnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerLMDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Right now just wraps TransformerDecoderConfig for simplicity.\nMight merge in a single class later once TransformerLM path is clarified.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer_lm&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerLMDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.TransformerModelConfig.architecture"><code>architecture (Literal[&#x27;transformer&#x27;])</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong>
<ul>
<li><code>_validate_transformer</code> ¬ª <code>all fields</code></li>
<li><a href="#eole.config.models.TransformerModelConfig.default_architecture"><code>default_architecture</code></a> ¬ª <code>all fields</code></li>
<li><a href="#eole.config.models.TransformerModelConfig.encoder_decoder_type"><code>encoder_decoder_type</code></a> ¬ª <code>all fields</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-architecture--literaltransformer--transformer"><em>field</em> architecture <em>: Literal[&#x27;transformer&#x27;]</em> <em>= &#x27;transformer&#x27;</em><a href="#field-architecture--literaltransformer--transformer" class="hash-link" aria-label="Direct link to field-architecture--literaltransformer--transformer" title="Direct link to field-architecture--literaltransformer--transformer">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><code>_validate_transformer</code></li>
<li><code>_validate_transformer_config</code></li>
<li><a href="#eole.config.models.TransformerModelConfig.default_architecture"><code>default_architecture</code></a></li>
<li><a href="#eole.config.models.TransformerModelConfig.encoder_decoder_type"><code>encoder_decoder_type</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-default_architecture----all-fieldssource-1"><em>validator</em> default_architecture  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L658-L665" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-default_architecture----all-fieldssource-1" class="hash-link" aria-label="Direct link to validator-default_architecture----all-fieldssource-1" title="Direct link to validator-default_architecture----all-fieldssource-1">‚Äã</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-encoder_decoder_type----all-fieldssource"><em>validator</em> encoder_decoder_type  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L642-L656" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-encoder_decoder_type----all-fieldssource" class="hash-link" aria-label="Direct link to validator-encoder_decoder_type----all-fieldssource" title="Direct link to validator-encoder_decoder_type----all-fieldssource">‚Äã</a></h4>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelstransformerlmmodelconfigsource"><em>pydantic model</em> eole.config.models.TransformerLMModelConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L672-L706" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelstransformerlmmodelconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelstransformerlmmodelconfigsource" title="Direct link to pydantic-model-eoleconfigmodelstransformerlmmodelconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.TransformerConfig"><code>TransformerConfig</code></a>, <a href="#eole.config.models.BaseModelConfig"><code>BaseModelConfig</code></a></p>
<p>Facilitate setting some transformer specific params at model level.</p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;TransformerLMModelConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;description&quot;: &quot;Facilitate setting some transformer specific params at model level.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Contains most of the args useful to build the Embeddings module.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of an encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer_lm&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;decoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of a decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden states. Overwrites [encoder/decoder].hidden_size if set.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in both encoder and decoder (will overwrite enc_layers/dec_layers).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_decoder_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a share weight matrix for the input and output word embeddings in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Decoder Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Share the word embeddings between encoder and decoder. Need to use shared vocabulary for this option.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;input_feed&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Input Feed&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;generator_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Which function to use for generating probabilities over the target vocabulary.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Generator Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_estimator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add estimator layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Estimator&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;left_pad&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable left-padding, useful for some LLMs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Left Pad&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;architecture&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_lm&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Architecture&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;EmbeddingsConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_enc&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Enc&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_dec&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Dec&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Absolute position encoding, see position_encoding_type. Necessary for non-RNN style models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Encoding&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_shift&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Positions IDS shift before making position embed dirty patch to cover for xlm-roberta-xl&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Shift&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;context_gate&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of context gate to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;source&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;target&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;both&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Context Gate&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bidirectional_encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bidirectional Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerLMDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Right now just wraps TransformerDecoderConfig for simplicity.\nMight merge in a single class later once TransformerLM path is clarified.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer_lm&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerLMDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.TransformerLMModelConfig.architecture"><code>architecture (Literal[&#x27;transformer_lm&#x27;])</code></a></li>
<li><a href="#eole.config.models.TransformerLMModelConfig.encoder"><code>encoder (None)</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong>
<ul>
<li><code>_validate_transformer</code> ¬ª <code>all fields</code></li>
<li><a href="#eole.config.models.TransformerLMModelConfig.default_architecture"><code>default_architecture</code></a> ¬ª <code>all fields</code></li>
<li><a href="#eole.config.models.TransformerLMModelConfig.encoder_decoder_type"><code>encoder_decoder_type</code></a> ¬ª <code>all fields</code></li>
<li><a href="#eole.config.models.BaseModelConfig.str_to_dict"><code>str_to_dict</code></a> ¬ª <a href="#eole.config.models.TransformerLMModelConfig.encoder"><code>encoder</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-architecture--literaltransformer_lm--transformer_lm"><em>field</em> architecture <em>: Literal[&#x27;transformer_lm&#x27;]</em> <em>= &#x27;transformer_lm&#x27;</em><a href="#field-architecture--literaltransformer_lm--transformer_lm" class="hash-link" aria-label="Direct link to field-architecture--literaltransformer_lm--transformer_lm" title="Direct link to field-architecture--literaltransformer_lm--transformer_lm">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><code>_validate_transformer</code></li>
<li><code>_validate_transformer_config</code></li>
<li><a href="#eole.config.models.TransformerLMModelConfig.default_architecture"><code>default_architecture</code></a></li>
<li><a href="#eole.config.models.TransformerLMModelConfig.encoder_decoder_type"><code>encoder_decoder_type</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-encoder--none--none"><em>field</em> encoder <em>: None</em> <em>= None</em><a href="#field-encoder--none--none" class="hash-link" aria-label="Direct link to field-encoder--none--none" title="Direct link to field-encoder--none--none">‚Äã</a></h4>
<p>Major parameters of an encoder.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><code>_validate_transformer</code></li>
<li><code>_validate_transformer_config</code></li>
<li><a href="#eole.config.models.TransformerLMModelConfig.default_architecture"><code>default_architecture</code></a></li>
<li><a href="#eole.config.models.TransformerLMModelConfig.encoder_decoder_type"><code>encoder_decoder_type</code></a></li>
<li><a href="#eole.config.models.BaseModelConfig.str_to_dict"><code>str_to_dict</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-default_architecture----all-fieldssource-2"><em>validator</em> default_architecture  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L694-L701" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-default_architecture----all-fieldssource-2" class="hash-link" aria-label="Direct link to validator-default_architecture----all-fieldssource-2" title="Direct link to validator-default_architecture----all-fieldssource-2">‚Äã</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-encoder_decoder_type----all-fieldssource-1"><em>validator</em> encoder_decoder_type  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L682-L692" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-encoder_decoder_type----all-fieldssource-1" class="hash-link" aria-label="Direct link to validator-encoder_decoder_type----all-fieldssource-1" title="Direct link to validator-encoder_decoder_type----all-fieldssource-1">‚Äã</a></h4>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rnn">RNN<a href="#rnn" class="hash-link" aria-label="Direct link to RNN" title="Direct link to RNN">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelsrnnconfigsource"><em>pydantic model</em> eole.config.models.RnnConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L115-L125" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelsrnnconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelsrnnconfigsource" title="Direct link to pydantic-model-eoleconfigmodelsrnnconfigsource">‚Äã</a></h3>
<p>Bases: <code>Config</code></p>
<p>Just to facilitate testing discriminator stuff.</p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;RnnConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;description&quot;: &quot;Just to facilitate testing discriminator stuff.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.RnnConfig.bridge"><code>bridge (bool)</code></a></li>
<li><a href="#eole.config.models.RnnConfig.rnn_type"><code>rnn_type (Literal[&#x27;LSTM&#x27;, &#x27;GRU&#x27;])</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-bridge--bool--false"><em>field</em> bridge <em>: bool</em> <em>= False</em><a href="#field-bridge--bool--false" class="hash-link" aria-label="Direct link to field-bridge--bool--false" title="Direct link to field-bridge--bool--false">‚Äã</a></h4>
<p>Have an additional layer between the last encoder state and the first decoder state (RNN specific).</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-rnn_type--literallstm-gru--lstm"><em>field</em> rnn_type <em>: Literal[&#x27;LSTM&#x27;, &#x27;GRU&#x27;]</em> <em>= &#x27;LSTM&#x27;</em><a href="#field-rnn_type--literallstm-gru--lstm" class="hash-link" aria-label="Direct link to field-rnn_type--literallstm-gru--lstm" title="Direct link to field-rnn_type--literallstm-gru--lstm">‚Äã</a></h4>
<p>The gate type to use in the RNNs.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelsrnnencoderconfigsource"><em>pydantic model</em> eole.config.models.RnnEncoderConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L128-L129" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelsrnnencoderconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelsrnnencoderconfigsource" title="Direct link to pydantic-model-eoleconfigmodelsrnnencoderconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.RnnConfig"><code>RnnConfig</code></a>, <a href="#eole.config.models.EncoderConfig"><code>EncoderConfig</code></a></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;brnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.RnnEncoderConfig.encoder_type"><code>encoder_type (Literal[&#x27;rnn&#x27;, &#x27;brnn&#x27;])</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-encoder_type--literalrnn-brnn--rnn"><em>field</em> encoder_type <em>: Literal[&#x27;rnn&#x27;, &#x27;brnn&#x27;]</em> <em>= &#x27;rnn&#x27;</em><a href="#field-encoder_type--literalrnn-brnn--rnn" class="hash-link" aria-label="Direct link to field-encoder_type--literalrnn-brnn--rnn" title="Direct link to field-encoder_type--literalrnn-brnn--rnn">‚Äã</a></h4>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelsrnndecoderconfigsource"><em>pydantic model</em> eole.config.models.RnnDecoderConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L132-L137" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelsrnndecoderconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelsrnndecoderconfigsource" title="Direct link to pydantic-model-eoleconfigmodelsrnndecoderconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.RnnConfig"><code>RnnConfig</code></a>, <a href="#eole.config.models.DecoderConfig"><code>DecoderConfig</code></a></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;context_gate&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Type of context gate to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;source&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;target&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;both&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Context Gate&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;bidirectional_encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Bidirectional Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.RnnDecoderConfig.bidirectional_encoder"><code>bidirectional_encoder (bool | None)</code></a></li>
<li><a href="#eole.config.models.RnnDecoderConfig.context_gate"><code>context_gate (Literal[&#x27;source&#x27;, &#x27;target&#x27;, &#x27;both&#x27;, None])</code></a></li>
<li><a href="#eole.config.models.RnnDecoderConfig.decoder_type"><code>decoder_type (Literal[&#x27;rnn&#x27;])</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-bidirectional_encoder--bool--none--false"><em>field</em> bidirectional_encoder <em>: bool | None</em> <em>= False</em><a href="#field-bidirectional_encoder--bool--none--false" class="hash-link" aria-label="Direct link to field-bidirectional_encoder--bool--none--false" title="Direct link to field-bidirectional_encoder--bool--none--false">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-context_gate--literalsource-target-both-none--none"><em>field</em> context_gate <em>: Literal[&#x27;source&#x27;, &#x27;target&#x27;, &#x27;both&#x27;, None]</em> <em>= None</em><a href="#field-context_gate--literalsource-target-both-none--none" class="hash-link" aria-label="Direct link to field-context_gate--literalsource-target-both-none--none" title="Direct link to field-context_gate--literalsource-target-both-none--none">‚Äã</a></h4>
<p>Type of context gate to use.</p>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-decoder_type--literalrnn--rnn"><em>field</em> decoder_type <em>: Literal[&#x27;rnn&#x27;]</em> <em>= &#x27;rnn&#x27;</em><a href="#field-decoder_type--literalrnn--rnn" class="hash-link" aria-label="Direct link to field-decoder_type--literalrnn--rnn" title="Direct link to field-decoder_type--literalrnn--rnn">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelsrnnmodelconfigsource"><em>pydantic model</em> eole.config.models.RnnModelConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L576-L602" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelsrnnmodelconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelsrnnmodelconfigsource" title="Direct link to pydantic-model-eoleconfigmodelsrnnmodelconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.RnnConfig"><code>RnnConfig</code></a>, <a href="#eole.config.models.BaseModelConfig"><code>BaseModelConfig</code></a></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;RnnModelConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Contains most of the args useful to build the Embeddings module.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;brnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;mean&quot;: &quot;#/$defs/MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;encoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/MeanEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of an encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer_lm&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;decoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of a decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden states. Overwrites [encoder/decoder].hidden_size if set.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in both encoder and decoder (will overwrite enc_layers/dec_layers).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_decoder_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a share weight matrix for the input and output word embeddings in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Decoder Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Share the word embeddings between encoder and decoder. Need to use shared vocabulary for this option.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;input_feed&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Input Feed&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;generator_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Which function to use for generating probabilities over the target vocabulary.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Generator Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_estimator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add estimator layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Estimator&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;left_pad&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable left-padding, useful for some LLMs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Left Pad&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;architecture&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Architecture&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;EmbeddingsConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_enc&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Enc&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_dec&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Dec&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Absolute position encoding, see position_encoding_type. Necessary for non-RNN style models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Encoding&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_shift&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Positions IDS shift before making position embed dirty patch to cover for xlm-roberta-xl&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Shift&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;MeanEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;context_gate&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of context gate to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;source&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;target&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;both&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Context Gate&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bidirectional_encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bidirectional Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;brnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerLMDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Right now just wraps TransformerDecoderConfig for simplicity.\nMight merge in a single class later once TransformerLM path is clarified.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer_lm&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerLMDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.RnnModelConfig.architecture"><code>architecture (Literal[&#x27;rnn&#x27;])</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong>
<ul>
<li><a href="#eole.config.models.RnnModelConfig.default_architecture"><code>default_architecture</code></a> ¬ª <code>all fields</code></li>
<li><a href="#eole.config.models.RnnModelConfig.encoder_decoder_type"><code>encoder_decoder_type</code></a> ¬ª <code>all fields</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-architecture--literalrnn--rnn"><em>field</em> architecture <em>: Literal[&#x27;rnn&#x27;]</em> <em>= &#x27;rnn&#x27;</em><a href="#field-architecture--literalrnn--rnn" class="hash-link" aria-label="Direct link to field-architecture--literalrnn--rnn" title="Direct link to field-architecture--literalrnn--rnn">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.RnnModelConfig.default_architecture"><code>default_architecture</code></a></li>
<li><a href="#eole.config.models.RnnModelConfig.encoder_decoder_type"><code>encoder_decoder_type</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-default_architecture----all-fieldssource-3"><em>validator</em> default_architecture  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L595-L602" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-default_architecture----all-fieldssource-3" class="hash-link" aria-label="Direct link to validator-default_architecture----all-fieldssource-3" title="Direct link to validator-default_architecture----all-fieldssource-3">‚Äã</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-encoder_decoder_type----all-fieldssource-2"><em>validator</em> encoder_decoder_type  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L579-L593" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-encoder_decoder_type----all-fieldssource-2" class="hash-link" aria-label="Direct link to validator-encoder_decoder_type----all-fieldssource-2" title="Direct link to validator-encoder_decoder_type----all-fieldssource-2">‚Äã</a></h4>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cnn">CNN<a href="#cnn" class="hash-link" aria-label="Direct link to CNN" title="Direct link to CNN">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelscnnconfigsource"><em>pydantic model</em> eole.config.models.CnnConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L140-L145" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelscnnconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelscnnconfigsource" title="Direct link to pydantic-model-eoleconfigmodelscnnconfigsource">‚Äã</a></h3>
<p>Bases: <code>Config</code></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;CnnConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.CnnConfig.cnn_kernel_width"><code>cnn_kernel_width (int)</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-cnn_kernel_width--int--3"><em>field</em> cnn_kernel_width <em>: int</em> <em>= 3</em><a href="#field-cnn_kernel_width--int--3" class="hash-link" aria-label="Direct link to field-cnn_kernel_width--int--3" title="Direct link to field-cnn_kernel_width--int--3">‚Äã</a></h4>
<p>Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelscnnencoderconfigsource"><em>pydantic model</em> eole.config.models.CnnEncoderConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L148-L149" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelscnnencoderconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelscnnencoderconfigsource" title="Direct link to pydantic-model-eoleconfigmodelscnnencoderconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.CnnConfig"><code>CnnConfig</code></a>, <a href="#eole.config.models.EncoderConfig"><code>EncoderConfig</code></a></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.CnnEncoderConfig.encoder_type"><code>encoder_type (Literal[&#x27;cnn&#x27;])</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-encoder_type--literalcnn--cnn"><em>field</em> encoder_type <em>: Literal[&#x27;cnn&#x27;]</em> <em>= &#x27;cnn&#x27;</em><a href="#field-encoder_type--literalcnn--cnn" class="hash-link" aria-label="Direct link to field-encoder_type--literalcnn--cnn" title="Direct link to field-encoder_type--literalcnn--cnn">‚Äã</a></h4>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelscnndecoderconfigsource"><em>pydantic model</em> eole.config.models.CnnDecoderConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L152-L153" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelscnndecoderconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelscnndecoderconfigsource" title="Direct link to pydantic-model-eoleconfigmodelscnndecoderconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.CnnConfig"><code>CnnConfig</code></a>, <a href="#eole.config.models.DecoderConfig"><code>DecoderConfig</code></a></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.CnnDecoderConfig.decoder_type"><code>decoder_type (Literal[&#x27;cnn&#x27;])</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-decoder_type--literalcnn--cnn"><em>field</em> decoder_type <em>: Literal[&#x27;cnn&#x27;]</em> <em>= &#x27;cnn&#x27;</em><a href="#field-decoder_type--literalcnn--cnn" class="hash-link" aria-label="Direct link to field-decoder_type--literalcnn--cnn" title="Direct link to field-decoder_type--literalcnn--cnn">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_validate_decoder_config</code></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pydantic-model-eoleconfigmodelscnnmodelconfigsource"><em>pydantic model</em> eole.config.models.CnnModelConfig<a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L605-L632" target="_blank" rel="noopener noreferrer">[source]</a><a href="#pydantic-model-eoleconfigmodelscnnmodelconfigsource" class="hash-link" aria-label="Direct link to pydantic-model-eoleconfigmodelscnnmodelconfigsource" title="Direct link to pydantic-model-eoleconfigmodelscnnmodelconfigsource">‚Äã</a></h3>
<p>Bases: <a href="#eole.config.models.CnnConfig"><code>CnnConfig</code></a>, <a href="#eole.config.models.BaseModelConfig"><code>BaseModelConfig</code></a></p>
<p></p><details class="details_lb9f alert alert--info details_b_Ee autodoc_pydantic_collapsable_json" data-collapsed="true"><summary>Show JSON schema</summary><div><div class="collapsibleContent_i85q">
<!-- -->
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;title&quot;: &quot;CnnModelConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;type&quot;: &quot;object&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;$ref&quot;: &quot;#/$defs/EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Contains most of the args useful to build the Embeddings module.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;brnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;mean&quot;: &quot;#/$defs/MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;encoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/MeanEncoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of an encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;decoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;discriminator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mapping&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;cnn&quot;: &quot;#/$defs/CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;rnn&quot;: &quot;#/$defs/RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;transformer_lm&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;propertyName&quot;: &quot;decoder_type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;oneOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/TransformerLMDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/CnnDecoderConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Major parameters of a decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Decoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden states. Overwrites [encoder/decoder].hidden_size if set.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Number of layers in both encoder and decoder (will overwrite enc_layers/dec_layers).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_decoder_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Use a share weight matrix for the input and output word embeddings in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Decoder Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;share_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Share the word embeddings between encoder and decoder. Need to use shared vocabulary for this option.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Share Embeddings&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;input_feed&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Input Feed&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;generator_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Which function to use for generating probabilities over the target vocabulary.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Generator Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;add_estimator&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Add estimator layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Add Estimator&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;left_pad&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Enable left-padding, useful for some LLMs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Left Pad&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;architecture&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Architecture&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;$defs&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;ActivationFunction&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;silu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-gelu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;gated-silu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;CnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;cnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;cnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;cnn_kernel_width&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of windows in the cnn, the kernel_size is (cnn_kernel_width, 1) in convolution layers.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Cnn Kernel Width&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;CnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;EmbeddingsConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src and tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_enc&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Enc&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;freeze_word_vecs_dec&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Freeze word embeddings on the encoder side.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Freeze Word Vecs Dec&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Absolute position encoding, see position_encoding_type. Necessary for non-RNN style models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Encoding&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_shift&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Positions IDS shift before making position embed dirty patch to cover for xlm-roberta-xl&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Position Shift&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;EmbeddingsConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;MeanEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;mean&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;MeanEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;PositionEncodingType&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SinusoidalConcat&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Learned&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Rotary&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Alibi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;PositionEncodingType&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;context_gate&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of context gate to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;source&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;target&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;both&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Context Gate&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bidirectional_encoder&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bidirectional Encoder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RnnEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rnn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;brnn&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;bridge&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Have an additional layer between the last encoder state and the first decoder state (RNN specific).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Bridge&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rnn_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The gate type to use in the RNNs.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;LSTM&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;GRU&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rnn Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RnnEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;RotaryPositionConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Configuration for rotary position embeddings used in transformer models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_interleave&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Interleave the head dimensions when rotary embeddings are applied. Otherwise the head dimensions are sliced in half. (True=default Llama from Meta (original), False= used by all HuggingFace models)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Interleave&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_theta&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary theta base length, 1e4 for Llama2.Mistral, 1e6 for Mixtral&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Theta&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rotary_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary dim when model requires it to be different to head dim.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Rotary Dim&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Specifies the type of RoPE scaling to be applied, if any.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Type&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;scaling_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Factor by which to scale RoPE embeddings.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Scaling Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;low_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the lower frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Low Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;high_freq_factor&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 4.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Scaling factor applied to the higher frequency components of RoPE.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;High Freq Factor&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;original_max_position_embeddings&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8192,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Original maximum position embeddings for RoPE scaling.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Original Max Position Embeddings&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;RotaryPositionConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerEncoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;encoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Encoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the encoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of encoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;src_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for src.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Src Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerEncoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;TransformerLMDecoderConfig&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;additionalProperties&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;description&quot;: &quot;Right now just wraps TransformerDecoderConfig for simplicity.\nMight merge in a single class later once TransformerLM path is clarified.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;decoder_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;const&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;transformer_lm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;transformer_lm&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Decoder Type&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layers&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of layers in the decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;hidden_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of decoder hidden states.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Hidden Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;tgt_word_vec_size&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Word embedding size for tgt.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Tgt Word Vec Size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;coverage_attn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Train a coverage attention layer.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Coverage Attn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_coverage&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for coverage loss of See et al (2017)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Coverage&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The attention type to use. (Luong=general, Bahdanau=MLP)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;dot&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;general&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;mlp&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  null</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;global_attention_function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Global attention function to use.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;softmax&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;sparsemax&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Global Attention Function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sliding_window&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Sliding window for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Sliding Window&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for transformer self-attention.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;transformer_ff&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Size of hidden transformer feed-forward.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Transformer Ff&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;relative_positions_buckets&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Enable relative position bias (https://github.com/google-research/text-to-text-transfer-transformer).&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Relative Positions Buckets&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;mlp_activation_fn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;$ref&quot;: &quot;#/$defs/ActivationFunction&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;relu&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;The activation function to use in MLP layer.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of layer normalization in transformer architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;enum&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;standard&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  &quot;rms&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;string&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;norm_eps&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 1e-06,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer norm epsilon.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Norm Eps&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;shared_layer_norm&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use a shared layer_norm in parallel residual attention. Note: must be True for Falcon 7B, False for Falcon 40B, same for GPT-J and GPT-NeoX models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Shared Layer Norm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_qkvbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of Query/Key/Value in MHA. Note: this will add bias to output projection layer too.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Qkvbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;heads_kv&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of heads for KV. heads_kv=heads if None, else number of heads for KV(e.g. Falcon 40B)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Heads Kv&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;head_dim&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Head dimension when this needs to be different vs hidden_size // heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Head Dim&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;add_ffnbias&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Add bias to nn.Linear of MLP FFN.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Add Ffnbias&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;parallel_residual&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Use parallel residual in decoder layer. Note: this is used by GPT-J / Falcon Architecture.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Parallel Residual&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts for MoE models.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;num_experts_per_tok&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of experts per token.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Num Experts Per Tok&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;position_encoding_type&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/PositionEncodingType&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: &quot;SinusoidalInterleaved&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Type of positional encoding.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;n_positions&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Two casesCase 1: Absolute number of positions to learn position embeddings on (position_encoding_type: Learned)Case 2: Max Relative PositionsIn the case of position_encoding_type: Relative&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;N Positions&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;rope_config&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;anyOf&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;$ref&quot;: &quot;#/$defs/RotaryPositionConfig&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                     &quot;type&quot;: &quot;null&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: null,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Rotary position config, if relevant.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;aan_useffn&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Turn on the FFN layer in the AAN decoder.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Aan Useffn&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_layer&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: -2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Layer number which has to be supervised.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Layer&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;alignment_heads&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Number of cross attention heads per layer to supervise with.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Alignment Heads&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;integer&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;full_context_alignment&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Whether alignment is conditioned on full target context.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Full Context Alignment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;boolean&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;lambda_align&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;default&quot;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;description&quot;: &quot;Lambda value for alignement loss of Garg et al, 2019 (https://arxiv.org/abs/1909.02074)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;title&quot;: &quot;Lambda Align&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               &quot;type&quot;: &quot;number&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;title&quot;: &quot;TransformerLMDecoderConfig&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">         &quot;type&quot;: &quot;object&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   &quot;additionalProperties&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</div></div></details><p></p>
<ul>
<li><strong>Config:</strong>
<ul>
<li><strong>validate_assignment</strong>: <em>bool = True</em></li>
<li><strong>validate_default</strong>: <em>bool = True</em></li>
<li><strong>use_enum_values</strong>: <em>bool = True</em></li>
<li><strong>extra</strong>: <em>str = forbid</em></li>
<li><strong>protected_namespaces</strong>: <em>tuple = ()</em></li>
</ul>
</li>
<li><strong>Fields:</strong>
<ul>
<li><a href="#eole.config.models.CnnModelConfig.architecture"><code>architecture (Literal[&#x27;cnn&#x27;])</code></a></li>
</ul>
</li>
<li><strong>Validators:</strong>
<ul>
<li><a href="#eole.config.models.CnnModelConfig.default_architecture"><code>default_architecture</code></a> ¬ª <code>all fields</code></li>
<li><a href="#eole.config.models.CnnModelConfig.encoder_decoder_type"><code>encoder_decoder_type</code></a> ¬ª <code>all fields</code></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="field-architecture--literalcnn--cnn"><em>field</em> architecture <em>: Literal[&#x27;cnn&#x27;]</em> <em>= &#x27;cnn&#x27;</em><a href="#field-architecture--literalcnn--cnn" class="hash-link" aria-label="Direct link to field-architecture--literalcnn--cnn" title="Direct link to field-architecture--literalcnn--cnn">‚Äã</a></h4>
<ul>
<li><strong>Validated by:</strong>
<ul>
<li><code>_override_values</code></li>
<li><code>_validate_model_config</code></li>
<li><a href="#eole.config.models.CnnModelConfig.default_architecture"><code>default_architecture</code></a></li>
<li><a href="#eole.config.models.CnnModelConfig.encoder_decoder_type"><code>encoder_decoder_type</code></a></li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-default_architecture----all-fieldssource-4"><em>validator</em> default_architecture  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L625-L632" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-default_architecture----all-fieldssource-4" class="hash-link" aria-label="Direct link to validator-default_architecture----all-fieldssource-4" title="Direct link to validator-default_architecture----all-fieldssource-4">‚Äã</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validator-encoder_decoder_type----all-fieldssource-3"><em>validator</em> encoder_decoder_type  <em>¬ª</em>  <em>all fields</em><a href="https://github.com/eole-nlp/eole/blob/master/eole/config/models.py#L608-L623" target="_blank" rel="noopener noreferrer">[source]</a><a href="#validator-encoder_decoder_type----all-fieldssource-3" class="hash-link" aria-label="Direct link to validator-encoder_decoder_type----all-fieldssource-3" title="Direct link to validator-encoder_decoder_type----all-fieldssource-3">‚Äã</a></h4></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/eole-nlp/eole/tree/main/docs/docs/reference/Config/models.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/eole/docs/reference/Config/inference"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Inference</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/eole/docs/reference/Config/run"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Main Entrypoints</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#base-configs" class="table-of-contents__link toc-highlight">Base Configs</a><ul><li><a href="#pydantic-model-eoleconfigmodelsbasemodelconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.BaseModelConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelsembeddingsconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.EmbeddingsConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelsencoderconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.EncoderConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelsdecoderconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.DecoderConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelscustommodelconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.CustomModelConfig[source]</a></li></ul></li><li><a href="#transformer" class="table-of-contents__link toc-highlight">Transformer</a><ul><li><a href="#pydantic-model-eoleconfigmodelstransformerconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.TransformerConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelstransformerencoderconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.TransformerEncoderConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelstransformerdecoderconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.TransformerDecoderConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelstransformerlmdecoderconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.TransformerLMDecoderConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelstransformermodelconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.TransformerModelConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelstransformerlmmodelconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.TransformerLMModelConfig[source]</a></li></ul></li><li><a href="#rnn" class="table-of-contents__link toc-highlight">RNN</a><ul><li><a href="#pydantic-model-eoleconfigmodelsrnnconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.RnnConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelsrnnencoderconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.RnnEncoderConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelsrnndecoderconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.RnnDecoderConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelsrnnmodelconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.RnnModelConfig[source]</a></li></ul></li><li><a href="#cnn" class="table-of-contents__link toc-highlight">CNN</a><ul><li><a href="#pydantic-model-eoleconfigmodelscnnconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.CnnConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelscnnencoderconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.CnnEncoderConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelscnndecoderconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.CnnDecoderConfig[source]</a></li><li><a href="#pydantic-model-eoleconfigmodelscnnmodelconfigsource" class="table-of-contents__link toc-highlight"><em>pydantic model</em> eole.config.models.CnnModelConfig[source]</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/eole/docs/">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/eole-nlp/eole/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/eole-nlp/eole" target="_blank" rel="noopener noreferrer" class="footer__link-item">Source<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">EOLE is an open-source toolkit and is licensed under the MIT license.</div></div></div></footer></div>
</body>
</html>